{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proud-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"not_merry_final.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wanted-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11796"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"mate_conts\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "urban-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.loc[data[\"mate_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intellectual-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"family_conts\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.loc[data[\"family_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "institutional-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "detailed-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "classical-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"family_conts\"]=data[\"family_conts\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9 ? !]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "australian-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=pd.read_csv(\"../data/thanks_yeobaya_2.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unavailable-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m.drop(data_m.loc[data_m[\"mate_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unknown-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m.drop(data_m.loc[data_m[\"family_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "partial-academy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10730 entries, 0 to 11090\n",
      "Data columns (total 37 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   auto_no                10730 non-null  int64  \n",
      " 1   reg_slct               10730 non-null  object \n",
      " 2   reg_mem_no             10730 non-null  int64  \n",
      " 3   reg_name               0 non-null      float64\n",
      " 4   reg_title              10730 non-null  object \n",
      " 5   reg_sex                10729 non-null  object \n",
      " 6   reg_age                10730 non-null  int64  \n",
      " 7   reg_nick               10730 non-null  object \n",
      " 8   reg_photo              7198 non-null   object \n",
      " 9   reg_photo_cnt          10730 non-null  int64  \n",
      " 10  reg_loc                10729 non-null  object \n",
      " 11  reg_job_detail         10727 non-null  object \n",
      " 12  reg_join_date          10730 non-null  object \n",
      " 13  reg_job                10730 non-null  float64\n",
      " 14  reg_point              10730 non-null  int64  \n",
      " 15  reg_conts              10730 non-null  object \n",
      " 16  reg_date               10729 non-null  object \n",
      " 17  reg_exit_date          10730 non-null  object \n",
      " 18  photo_cnt              10730 non-null  int64  \n",
      " 19  cert_salary_photo_cnt  10730 non-null  int64  \n",
      " 20  cert_career_photo_cnt  10730 non-null  int64  \n",
      " 21  cert_car_photo_cnt     10730 non-null  int64  \n",
      " 22  cert_certfc_photo_cnt  10730 non-null  int64  \n",
      " 23  cert_job_photo_cnt     10730 non-null  int64  \n",
      " 24  cert_gif_data_cnt      10730 non-null  int64  \n",
      " 25  cert_voice_data_cnt    10730 non-null  int64  \n",
      " 26  cert_mov_data_cnt      10730 non-null  int64  \n",
      " 27  auth_cnt               10730 non-null  int64  \n",
      " 28  mate_conts             10730 non-null  object \n",
      " 29  family_conts           10730 non-null  object \n",
      " 30  hit_cnt                10730 non-null  int64  \n",
      " 31  hit_m_cnt              10730 non-null  int64  \n",
      " 32  hit_f_cnt              10730 non-null  int64  \n",
      " 33  hit_n_cnt              10730 non-null  int64  \n",
      " 34  prt_slct               10730 non-null  object \n",
      " 35  ins_date               10730 non-null  object \n",
      " 36  gift_yn                10730 non-null  object \n",
      "dtypes: float64(2), int64(19), object(16)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civilian-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ethical-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m[\"family_conts\"]=data_m[\"family_conts\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9 ? !]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "facial-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=data.loc[:10729,['family_conts','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "closing-utilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>부모님 두분 아직은 건강하시고 형제로는 남동생 하나있답니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>부모님은 몇해전 귀농하셔서 시골에서 생활중입니다  부모님 형 모드 건강하며</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그냥 화목하게 지내고 있는중입니다  별다른거는 없네요  고부 갈등은 없을껍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나혼자입니다   언제부터인지는 모르지만 혼자입니다 만날수있다는거죠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>가족들은 다 결혼하고 저혼자 남아 있네요 누나들하고 사이좋게 지내고 있어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>전   23살된  아들  하나있읍니다   현재  직업군인으로   있읍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>음 안녕하세여 3남 3녀에 막내이구여 두분다 어릴적에 작고하셨네요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>원만한 가족관계로서 서로의 의사를 존중하고 서로의 집안일들을 의논하며 처리...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>일반적인 가정과 변반 다르지 않습니다   자기 소개란예 가족 이야기를 하려니 어색합니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10730 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            family_conts  label\n",
       "0                       부모님 두분 아직은 건강하시고 형제로는 남동생 하나있답니다      0\n",
       "1      삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...      0\n",
       "2              부모님은 몇해전 귀농하셔서 시골에서 생활중입니다  부모님 형 모드 건강하며      0\n",
       "3           그냥 화목하게 지내고 있는중입니다  별다른거는 없네요  고부 갈등은 없을껍니다       0\n",
       "4                   나혼자입니다   언제부터인지는 모르지만 혼자입니다 만날수있다는거죠      0\n",
       "...                                                  ...    ...\n",
       "10725          가족들은 다 결혼하고 저혼자 남아 있네요 누나들하고 사이좋게 지내고 있어요      0\n",
       "10726          전   23살된  아들  하나있읍니다   현재  직업군인으로   있읍니다       0\n",
       "10727               음 안녕하세여 3남 3녀에 막내이구여 두분다 어릴적에 작고하셨네요      0\n",
       "10728       원만한 가족관계로서 서로의 의사를 존중하고 서로의 집안일들을 의논하며 처리...      0\n",
       "10729   일반적인 가정과 변반 다르지 않습니다   자기 소개란예 가족 이야기를 하려니 어색합니다      0\n",
       "\n",
       "[10730 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "physical-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=data_m.loc[:,['family_conts','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eligible-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자녀는 성인이며 배우자와 함께 살고 가끔 톡이나 통화함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>안녕하세요 부모님은 다계시고  건강히 지내고 있습니다  잘부탁드릴께요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>누나 두분 그리고 제 아들 딸  19살 16살 사정상  같이 살지는  않고요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>딸아이4살때부터 쭈욱 둘이였습니다   어느덧 딸아이가 시집갈나이가 되어서 지금은 늘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위로딸  아들 남매 를두었습니다  딸은서울에서 공직생활하고있으며   아들은 대구에있...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>제목숨보다도 소중한 아버지십니다  제고향도 서울이고 아버지도 혼자계시니 멀리있는분은...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>어떠한 상황이 있어도 항상 저를 응원하고 격려하는 의리 넘치는 멋진 사람들입니다  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>여동생은 중 선생님이구여 매제는 법무사랍니다 막내남동생은반도체기계 엔지니어로 늘 바...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>1남 1녀를 두고 있고요   둘 다 미국 주류사회에서 인정받고 있어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>평범한 집안에서 아들들에 딸하나로 조금은 엄하게 자라 버릇없다는 소리들어본적은 없지...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10730 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            family_conts  label\n",
       "0                    자녀는 성인이며 배우자와 함께 살고 가끔 톡이나 통화함           1\n",
       "1                 안녕하세요 부모님은 다계시고  건강히 지내고 있습니다  잘부탁드릴께요      1\n",
       "2             누나 두분 그리고 제 아들 딸  19살 16살 사정상  같이 살지는  않고요      1\n",
       "3      딸아이4살때부터 쭈욱 둘이였습니다   어느덧 딸아이가 시집갈나이가 되어서 지금은 늘...      1\n",
       "4      위로딸  아들 남매 를두었습니다  딸은서울에서 공직생활하고있으며   아들은 대구에있...      1\n",
       "...                                                  ...    ...\n",
       "11043  제목숨보다도 소중한 아버지십니다  제고향도 서울이고 아버지도 혼자계시니 멀리있는분은...      1\n",
       "11085  어떠한 상황이 있어도 항상 저를 응원하고 격려하는 의리 넘치는 멋진 사람들입니다  ...      1\n",
       "11088  여동생은 중 선생님이구여 매제는 법무사랍니다 막내남동생은반도체기계 엔지니어로 늘 바...      1\n",
       "11089            1남 1녀를 두고 있고요   둘 다 미국 주류사회에서 인정받고 있어요       1\n",
       "11090  평범한 집안에서 아들들에 딸하나로 조금은 엄하게 자라 버릇없다는 소리들어본적은 없지...      1\n",
       "\n",
       "[10730 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "impaired-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.concat([train1,train2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sensitive-spain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>부모님 두분 아직은 건강하시고 형제로는 남동생 하나있답니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>부모님은 몇해전 귀농하셔서 시골에서 생활중입니다  부모님 형 모드 건강하며</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그냥 화목하게 지내고 있는중입니다  별다른거는 없네요  고부 갈등은 없을껍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나혼자입니다   언제부터인지는 모르지만 혼자입니다 만날수있다는거죠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>제목숨보다도 소중한 아버지십니다  제고향도 서울이고 아버지도 혼자계시니 멀리있는분은...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>어떠한 상황이 있어도 항상 저를 응원하고 격려하는 의리 넘치는 멋진 사람들입니다  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>여동생은 중 선생님이구여 매제는 법무사랍니다 막내남동생은반도체기계 엔지니어로 늘 바...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>1남 1녀를 두고 있고요   둘 다 미국 주류사회에서 인정받고 있어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>평범한 집안에서 아들들에 딸하나로 조금은 엄하게 자라 버릇없다는 소리들어본적은 없지...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            family_conts  label\n",
       "0                       부모님 두분 아직은 건강하시고 형제로는 남동생 하나있답니다      0\n",
       "1      삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...      0\n",
       "2              부모님은 몇해전 귀농하셔서 시골에서 생활중입니다  부모님 형 모드 건강하며      0\n",
       "3           그냥 화목하게 지내고 있는중입니다  별다른거는 없네요  고부 갈등은 없을껍니다       0\n",
       "4                   나혼자입니다   언제부터인지는 모르지만 혼자입니다 만날수있다는거죠      0\n",
       "...                                                  ...    ...\n",
       "11043  제목숨보다도 소중한 아버지십니다  제고향도 서울이고 아버지도 혼자계시니 멀리있는분은...      1\n",
       "11085  어떠한 상황이 있어도 항상 저를 응원하고 격려하는 의리 넘치는 멋진 사람들입니다  ...      1\n",
       "11088  여동생은 중 선생님이구여 매제는 법무사랍니다 막내남동생은반도체기계 엔지니어로 늘 바...      1\n",
       "11089            1남 1녀를 두고 있고요   둘 다 미국 주류사회에서 인정받고 있어요       1\n",
       "11090  평범한 집안에서 아들들에 딸하나로 조금은 엄하게 자라 버릇없다는 소리들어본적은 없지...      1\n",
       "\n",
       "[21460 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "herbal-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "multiple-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data_family.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "concrete-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_data[\"family_conts\"]\n",
    "y=train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "listed-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "subjective-terminology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0      1  0\n",
       "1      1  0\n",
       "2      1  0\n",
       "3      1  0\n",
       "4      1  0\n",
       "...   .. ..\n",
       "21455  0  1\n",
       "21456  0  1\n",
       "21457  0  1\n",
       "21458  0  1\n",
       "21459  0  1\n",
       "\n",
       "[21460 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "offensive-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caring-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16077      이쁘고  똑똑한  딸아이  하나랑  살고 있어요 평범하고  이쁘게  알콩달콩 살아요 \n",
       "9683     어머니와 누나 저 남동생 2남1녀입니다  모두 둥굴둥굴 동네에서는 인성이좋은집으로 ...\n",
       "6521     새아버지 어머니 누나 저 이렇게4인 가족입니다  어릴때 아버지가 돌아가셔서 어머니가...\n",
       "16074                부모님은 고향에사시고 저는혼자지내고 딸은얼마전에 독립해서 살고있어요\n",
       "14920          딸 둘 중3 중2 같이 살고있구요  엄마 오빠 각각 따로  열심히 살고있습니다\n",
       "                               ...                        \n",
       "6400     저는 1남 1녀중 막내로 가족 모두 건강하고 행복하게 잘살고있습니다   아버지는 공...\n",
       "15288        아들은건설회사다니고 딸은커피숍하고잇어요 애들은 자기할일하고있으니 자식걱정은없어요 \n",
       "11513                     고향에 아버지만 계시고  3남2녀중 넷째입니다  감사합니다\n",
       "1688             어머님 남동생  그리고 저어머님 며느리언제쯤 볼 수 있을까 기다리중 입니다\n",
       "5994           가족들 모두  건강하고  잘 지내고 있습니다  저는  1남1녀 둘째 이고요  \n",
       "Name: family_conts, Length: 16095, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "injured-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15450    대학생 3학년 딸과 부모님 모두 건강 합니다  서로 아끼고 사랑하는 믿음안에  있는...\n",
       "2400         대한민국의 평범한 가정입니다   누나들은 모두 시집갔고 이렇게 저만 남았네요   \n",
       "20192                  아버지 어머니 저와 여동생 있습니다   여동생은 시집갔습니다  \n",
       "15896                부모님은 다돌아 가시고  자녀는 직장인 딸1 대학생인 아들1 있어요\n",
       "10356                     건강하신 부모님과 장가간 남동생에 최근 조카까지 생겼답니다\n",
       "                               ...                        \n",
       "18842       아버지와어머니남동생 부모님은강원도삼척계시구 두분다너무 정적인분들이셔서너무좋아요   \n",
       "14288             가족4명   있고  택배  돌봄     등등  엄마   아빠  남동생 나\n",
       "16005    2남3녀중 막내로 태어나서 가족듷 의 많은 사랑읗 받고 자림  내가족은 딸 하나 유학중!\n",
       "19133    신세대이시며 세련됐고 재밌는 부모님 외 6자매 각자 건강관리 잘하며 자주연락하고삽니다  \n",
       "17207                      저는 부모는 없어요  딸2인데 모두 출가  저혼자 살아요\n",
       "Name: family_conts, Length: 5365, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "seeing-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "intellectual-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_txt=[]\n",
    "for sentence in X_train:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence)#토큰화\n",
    "    X_train_txt.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "smoking-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_txt=[]\n",
    "for sentence in X_test:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence)#토큰화\n",
    "    X_test_txt.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aware-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['이쁘고', '똑똑한', '딸아이', '하나', '랑', '살', '고', '있어요', '평범하고', '이쁘게', '알콩달콩', '살아요'], ['어머니', '와', '누나', '저', '남동생', '2', '남', '1', '녀', '입니다', '모두', '둥굴둥굴', '동네', '에서는', '인성', '이', '좋은', '집', '으로', '통', '하구요', '좋아요', 'ㅎ'], ['새아버지', '어머니', '누나', '저', '이렇게', '4', '인', '가족', '입니다', '어릴', '때', '아버지', '가', '돌아가셔서', '어머니', '가', '고생', '을', '많이', '하셔서', '어머니', '께', '잘', '할', '겁니다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_txt[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "improved-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['대학생', '3', '학년', '딸', '과', '부모님', '모두', '건강', '합니다', '서로', '아끼고', '사랑', '하는', '믿음', '안', '에', '있는', '복된', '가정', '입니다'], ['대한민국', '의', '평범한', '가정', '입니다', '누나', '들', '은', '모두', '시집갔고', '이렇게', '저만', '남았네요'], ['아버지', '어머니', '저', '와', '여동생', '있습니다', '여동생', '은', '시집갔습니다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_txt[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "alive-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "shared-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame([tokenizer.word_counts.keys(),\n",
    "                       tokenizer.word_counts.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "conventional-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = word_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "straight-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.columns=['word','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "behind-integrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>은</td>\n",
       "      <td>10351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>는</td>\n",
       "      <td>6572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>고</td>\n",
       "      <td>5919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>에</td>\n",
       "      <td>5411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>부모님</td>\n",
       "      <td>5049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>딸하나있습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10823</th>\n",
       "      <td>광저우</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10826</th>\n",
       "      <td>좋아할거예요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>합치</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>지자체</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count\n",
       "54           은  10351\n",
       "58           는   6572\n",
       "6            고   5919\n",
       "56           에   5411\n",
       "53         부모님   5049\n",
       "...        ...    ...\n",
       "10822  딸하나있습니다      1\n",
       "10823      광저우      1\n",
       "10826   좋아할거예요      1\n",
       "10828       합치      1\n",
       "19268      지자체      1\n",
       "\n",
       "[19269 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "english-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=19300\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train_txt)\n",
    "X_train=tokenizer.texts_to_sequences(X_train_txt)\n",
    "X_test=tokenizer.texts_to_sequences(X_test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "national-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1511, 2838, 237, 81, 104, 10, 3, 49, 393, 1390, 342, 130], [15, 41, 33, 13, 42, 31, 32, 30, 39, 8, 27, 8510, 1805, 1649, 895, 7, 70, 118, 52, 1269, 642, 436, 203], [2839, 15, 33, 13, 109, 79, 86, 11, 8, 534, 170, 23, 25, 683, 15, 25, 2418, 12, 169, 308, 15, 457, 24, 165, 649]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "affected-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233, 53, 195, 26, 20, 5, 27, 404, 57, 76, 1388, 94, 97, 974, 128, 4, 129, 37, 8], [1492, 47, 96, 37, 8, 33, 6, 1, 27, 1237, 109, 108, 625]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "after-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "suspected-lunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "antique-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "lucky-preparation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "modular-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "divine-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_len = [len(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adverse-interim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.436e+03, 9.760e+03, 1.913e+03, 5.040e+02, 1.850e+02, 1.060e+02,\n",
       "        9.100e+01, 7.100e+01, 2.500e+01, 4.000e+00]),\n",
       " array([  0. ,  13.9,  27.8,  41.7,  55.6,  69.5,  83.4,  97.3, 111.2,\n",
       "        125.1, 139. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "finite-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=130\n",
    "X_train_pad=pad_sequences(X_train,maxlen=max_len)\n",
    "X_test_pad=pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vocal-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1390,  342,  130],\n",
       "       [   0,    0,    0, ...,  642,  436,  203],\n",
       "       [   0,    0,    0, ...,   24,  165,  649],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  973,    8,  664],\n",
       "       [   0,    0,    0, ..., 4619,   21,    8],\n",
       "       [   0,    0,    0, ...,  111,    7,  225]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pointed-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "filled-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../model/fam_text_model-{epoch:02d}-{val_accuracy:.4f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "raised-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(filename,\n",
    "                     monitor='val_accuracy',\n",
    "                     verbose=1,\n",
    "                     save_best_only=True)\n",
    "es = EarlyStopping(monitor=\"val_accuracy\",patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "official-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unavailable-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020D98B308C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020D98B308C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.6482WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020DB77BCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020DB77BCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68388, saving model to ../model\\fam_text_model-01-0.6839.hdf5\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.6342 - accuracy: 0.6482 - val_loss: 0.6470 - val_accuracy: 0.6839\n",
      "Epoch 2/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7405\n",
      "Epoch 00002: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.5364 - accuracy: 0.7404 - val_loss: 0.6083 - val_accuracy: 0.6766\n",
      "Epoch 3/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8082\n",
      "Epoch 00003: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.4270 - accuracy: 0.8082 - val_loss: 0.7021 - val_accuracy: 0.6654\n",
      "Epoch 4/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8515\n",
      "Epoch 00004: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.3437 - accuracy: 0.8515 - val_loss: 0.7966 - val_accuracy: 0.6613\n",
      "Epoch 5/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.8806\n",
      "Epoch 00005: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.2758 - accuracy: 0.8806 - val_loss: 0.9670 - val_accuracy: 0.6419\n",
      "Epoch 6/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9075\n",
      "Epoch 00006: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.2147 - accuracy: 0.9075 - val_loss: 1.0453 - val_accuracy: 0.6367\n",
      "Epoch 7/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9211\n",
      "Epoch 00007: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.1814 - accuracy: 0.9211 - val_loss: 1.2012 - val_accuracy: 0.6421\n",
      "Epoch 8/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9348\n",
      "Epoch 00008: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 76s 47ms/step - loss: 0.1524 - accuracy: 0.9348 - val_loss: 1.2161 - val_accuracy: 0.6326\n",
      "Epoch 9/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9446\n",
      "Epoch 00009: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.1295 - accuracy: 0.9446 - val_loss: 1.4230 - val_accuracy: 0.6227\n",
      "Epoch 10/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9552\n",
      "Epoch 00010: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.1054 - accuracy: 0.9552 - val_loss: 1.7462 - val_accuracy: 0.6293\n",
      "Epoch 11/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9599\n",
      "Epoch 00011: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 75s 46ms/step - loss: 0.0936 - accuracy: 0.9599 - val_loss: 1.8734 - val_accuracy: 0.6311\n",
      "Epoch 12/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9661\n",
      "Epoch 00012: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.0835 - accuracy: 0.9661 - val_loss: 1.6032 - val_accuracy: 0.6270\n",
      "Epoch 13/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9683\n",
      "Epoch 00013: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0744 - accuracy: 0.9683 - val_loss: 1.3537 - val_accuracy: 0.6259\n",
      "Epoch 14/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9737\n",
      "Epoch 00014: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0677 - accuracy: 0.9737 - val_loss: 1.8786 - val_accuracy: 0.6138\n",
      "Epoch 15/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9788\n",
      "Epoch 00015: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0555 - accuracy: 0.9788 - val_loss: 2.0552 - val_accuracy: 0.6239\n",
      "Epoch 16/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9807\n",
      "Epoch 00016: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.0507 - accuracy: 0.9807 - val_loss: 2.3657 - val_accuracy: 0.6116\n",
      "Epoch 17/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9847\n",
      "Epoch 00017: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 46ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 2.2617 - val_accuracy: 0.6110\n",
      "Epoch 18/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9848\n",
      "Epoch 00018: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0410 - accuracy: 0.9848 - val_loss: 2.2414 - val_accuracy: 0.6220\n",
      "Epoch 19/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9883\n",
      "Epoch 00019: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0357 - accuracy: 0.9883 - val_loss: 2.1426 - val_accuracy: 0.6188\n",
      "Epoch 20/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9891\n",
      "Epoch 00020: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.0296 - accuracy: 0.9891 - val_loss: 2.3455 - val_accuracy: 0.6196\n",
      "Epoch 21/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9904\n",
      "Epoch 00021: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 45ms/step - loss: 0.0246 - accuracy: 0.9904 - val_loss: 2.4794 - val_accuracy: 0.6091\n",
      "Epoch 22/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 00022: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 74s 46ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 3.0203 - val_accuracy: 0.6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9925\n",
      "Epoch 00023: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 73s 46ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 2.6362 - val_accuracy: 0.6075\n",
      "Epoch 24/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9927\n",
      "Epoch 00024: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 45ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 2.8397 - val_accuracy: 0.6209\n",
      "Epoch 25/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9943\n",
      "Epoch 00025: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 2.6935 - val_accuracy: 0.5935\n",
      "Epoch 26/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9948\n",
      "Epoch 00026: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 2.3792 - val_accuracy: 0.6108\n",
      "Epoch 27/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9938\n",
      "Epoch 00027: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 2.6700 - val_accuracy: 0.6149\n",
      "Epoch 28/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 00028: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 2.8054 - val_accuracy: 0.6034\n",
      "Epoch 29/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 00029: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 2.5356 - val_accuracy: 0.6026\n",
      "Epoch 30/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9958\n",
      "Epoch 00030: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 2.8064 - val_accuracy: 0.6106\n",
      "Epoch 31/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00031: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 3.3902 - val_accuracy: 0.6136\n",
      "Epoch 32/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 00032: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 2.4480 - val_accuracy: 0.6084\n",
      "Epoch 33/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 00033: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 3.0597 - val_accuracy: 0.6054\n",
      "Epoch 34/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 00034: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 2.7951 - val_accuracy: 0.6123\n",
      "Epoch 35/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 00035: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 2.5866 - val_accuracy: 0.6075\n",
      "Epoch 36/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00036: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 3.3318 - val_accuracy: 0.6106\n",
      "Epoch 37/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00037: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 2.8435 - val_accuracy: 0.6095\n",
      "Epoch 38/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00038: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 3.1010 - val_accuracy: 0.6093\n",
      "Epoch 39/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 00039: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 3.2057 - val_accuracy: 0.6104\n",
      "Epoch 40/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 00040: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 3.1806 - val_accuracy: 0.6134\n",
      "Epoch 41/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 00041: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 3.3539 - val_accuracy: 0.6045\n",
      "Epoch 42/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00042: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 3.7142 - val_accuracy: 0.6091\n",
      "Epoch 43/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 2.6500 - val_accuracy: 0.6047\n",
      "Epoch 44/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 00044: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 3.1080 - val_accuracy: 0.6140\n",
      "Epoch 45/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00045: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 3.5523 - val_accuracy: 0.6048\n",
      "Epoch 46/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 00046: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 3.1472 - val_accuracy: 0.6099\n",
      "Epoch 47/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9968\n",
      "Epoch 00047: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 2.8590 - val_accuracy: 0.6127\n",
      "Epoch 48/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 00048: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 3.4221 - val_accuracy: 0.6043\n",
      "Epoch 49/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n",
      "Epoch 00049: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 3.0464 - val_accuracy: 0.6116\n",
      "Epoch 50/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00050: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 3.9457 - val_accuracy: 0.6043\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 00051: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 2.7363 - val_accuracy: 0.6076\n",
      "Epoch 52/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9970\n",
      "Epoch 00052: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 2.8211 - val_accuracy: 0.6121\n",
      "Epoch 53/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 00053: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 3.2985 - val_accuracy: 0.6192\n",
      "Epoch 54/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 00054: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 4.2353 - val_accuracy: 0.6116\n",
      "Epoch 55/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 00055: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 3.8716 - val_accuracy: 0.6095\n",
      "Epoch 56/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 00056: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 3.1041 - val_accuracy: 0.6082\n",
      "Epoch 57/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 00057: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 3.5735 - val_accuracy: 0.6069\n",
      "Epoch 58/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 00058: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 3.7769 - val_accuracy: 0.6065\n",
      "Epoch 59/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00059: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 45ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 3.5929 - val_accuracy: 0.6116\n",
      "Epoch 60/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00060: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 3.4456 - val_accuracy: 0.6144\n",
      "Epoch 61/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00061: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 3.7386 - val_accuracy: 0.6048\n",
      "Epoch 62/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 00062: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 3.2736 - val_accuracy: 0.6058\n",
      "Epoch 63/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00063: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 3.4418 - val_accuracy: 0.6047\n",
      "Epoch 64/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 00064: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 3.2519 - val_accuracy: 0.6173\n",
      "Epoch 65/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 00065: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 3.2972 - val_accuracy: 0.6071\n",
      "Epoch 66/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00066: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 3.7020 - val_accuracy: 0.5991\n",
      "Epoch 67/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 00067: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 3.4250 - val_accuracy: 0.5976\n",
      "Epoch 68/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00068: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 2.7366 - val_accuracy: 0.6097\n",
      "Epoch 69/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00069: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 3.8531 - val_accuracy: 0.6121\n",
      "Epoch 70/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00070: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 3.6392 - val_accuracy: 0.6054\n",
      "Epoch 71/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00071: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 4.0414 - val_accuracy: 0.6024\n",
      "Epoch 72/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 00072: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 3.9352 - val_accuracy: 0.6093\n",
      "Epoch 73/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 00073: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 3.3201 - val_accuracy: 0.6091\n",
      "Epoch 74/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00074: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 3.2460 - val_accuracy: 0.6211\n",
      "Epoch 75/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 00075: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 45ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 3.2543 - val_accuracy: 0.6082\n",
      "Epoch 76/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00076: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 44ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 3.6075 - val_accuracy: 0.6186\n",
      "Epoch 77/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00077: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 3.1483 - val_accuracy: 0.6078\n",
      "Epoch 78/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 00078: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 3.5518 - val_accuracy: 0.6024\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00079: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 3.0543 - val_accuracy: 0.6099\n",
      "Epoch 80/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00080: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 2.8608 - val_accuracy: 0.6062\n",
      "Epoch 81/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 00081: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 45ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 2.8526 - val_accuracy: 0.6076\n",
      "Epoch 82/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00082: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 2.7390 - val_accuracy: 0.6091\n",
      "Epoch 83/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 00083: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 72s 45ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 3.6867 - val_accuracy: 0.6123\n",
      "Epoch 84/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00084: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 3.4796 - val_accuracy: 0.6162\n",
      "Epoch 85/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00085: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 2.9809 - val_accuracy: 0.6104\n",
      "Epoch 86/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00086: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 3.4411 - val_accuracy: 0.6166\n",
      "Epoch 87/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9988\n",
      "Epoch 00087: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 3.2016 - val_accuracy: 0.6185\n",
      "Epoch 88/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00088: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 3.7204 - val_accuracy: 0.6140\n",
      "Epoch 89/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00089: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 3.3449 - val_accuracy: 0.6045\n",
      "Epoch 90/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 00090: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 71s 44ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 3.0343 - val_accuracy: 0.6039\n",
      "Epoch 91/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9982\n",
      "Epoch 00091: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 3.0207 - val_accuracy: 0.5981\n",
      "Epoch 92/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 00092: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 3.0381 - val_accuracy: 0.6060\n",
      "Epoch 93/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 00093: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 2.9874 - val_accuracy: 0.6134\n",
      "Epoch 94/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 00094: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 44ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 3.2556 - val_accuracy: 0.6127\n",
      "Epoch 95/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00095: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 3.3690 - val_accuracy: 0.6050\n",
      "Epoch 96/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00096: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 3.3802 - val_accuracy: 0.6190\n",
      "Epoch 97/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00097: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 3.3566 - val_accuracy: 0.6155\n",
      "Epoch 98/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9979\n",
      "Epoch 00098: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 2.8755 - val_accuracy: 0.6134\n",
      "Epoch 99/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 00099: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 3.5010 - val_accuracy: 0.6129\n",
      "Epoch 100/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00100: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 70s 43ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 3.7080 - val_accuracy: 0.6048\n",
      "Epoch 101/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9978\n",
      "Epoch 00101: val_accuracy did not improve from 0.68388\n",
      "1610/1610 [==============================] - 69s 43ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 2.9851 - val_accuracy: 0.6028\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(max_words,100))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history=model.fit(X_train_pad,y_train,epochs=1000,batch_size=10,\n",
    "                  validation_data=(X_test_pad,y_test), callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "affiliated-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    sentence_before=[]\n",
    "    sentence_before.append(sent)\n",
    "    sent_txt=[]\n",
    "    for sentence in sentence_before:\n",
    "        temp_X=[]\n",
    "        temp_X=okt.morphs(sentence)\n",
    "        sent_txt.append(temp_X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_words=19300\n",
    "    tokenizer=Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(sent_txt)\n",
    "    f_data=tokenizer.texts_to_sequences(sent_txt)\n",
    "    max_len=130\n",
    "    data_pad=pad_sequences(f_data,maxlen=max_len)\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    p=model.predict(data_pad)[0][1]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "wrong-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=\"부모님 두분과 같이 생활 하고 있습니다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "russian-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053284395"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
