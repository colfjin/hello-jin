{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    spelled_sent = spell_checker.check(text)\n",
    "    hanspell_sent = spelled_sent.checked \n",
    "    return hanspell_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"not_merry_final.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11796"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"mate_conts\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.loc[data[\"mate_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"family_conts\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.loc[data[\"family_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97568 entries, 0 to 110868\n",
      "Data columns (total 89 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   mem_no            97568 non-null  int64  \n",
      " 1   mem_sex           97568 non-null  object \n",
      " 2   mem_loc           97568 non-null  object \n",
      " 3   mem_birth_year    97568 non-null  int64  \n",
      " 4   mem_birth_month   97568 non-null  int64  \n",
      " 5   mem_birth_ddi     97568 non-null  object \n",
      " 6   rprsn_mov_yn      97568 non-null  object \n",
      " 7   photo_cnt         97568 non-null  int64  \n",
      " 8   mate_conts        97568 non-null  object \n",
      " 9   mate_job          97568 non-null  object \n",
      " 10  mate_ann_salary   97568 non-null  object \n",
      " 11  mate_height       97568 non-null  int64  \n",
      " 12  mate_weight       97568 non-null  int64  \n",
      " 13  mate_blood        97568 non-null  object \n",
      " 14  mate_religion     97568 non-null  object \n",
      " 15  mate_car          97568 non-null  object \n",
      " 16  mate_career       97568 non-null  object \n",
      " 17  mate_style        97568 non-null  object \n",
      " 18  mate_charc        97568 non-null  object \n",
      " 19  mate_hobby        97568 non-null  object \n",
      " 20  mate_offspring_m  97568 non-null  int64  \n",
      " 21  mate_offspring_f  97568 non-null  int64  \n",
      " 22  htown_loc         97568 non-null  object \n",
      " 23  wed_plan          97568 non-null  object \n",
      " 24  fashion_style     97568 non-null  object \n",
      " 25  divorce_rslt      97568 non-null  object \n",
      " 26  brothers_sisters  97568 non-null  object \n",
      " 27  possess_property  97568 non-null  object \n",
      " 28  study_abroad      97568 non-null  object \n",
      " 29  favor_food        97568 non-null  object \n",
      " 30  parents_slct      97568 non-null  object \n",
      " 31  divorce_year      35765 non-null  float64\n",
      " 32  child_raise       97568 non-null  object \n",
      " 33  family_conts      97568 non-null  object \n",
      " 34  smoke_slct        97568 non-null  object \n",
      " 35  drink_slct        97568 non-null  object \n",
      " 36  health_slct       97568 non-null  object \n",
      " 37  secret_yn         97568 non-null  object \n",
      " 38  my_point_cont     97568 non-null  int64  \n",
      " 39  my_hd_yn          97568 non-null  object \n",
      " 40  기타                97568 non-null  int64  \n",
      " 41  음주가무              97568 non-null  int64  \n",
      " 42  애완동물              97568 non-null  int64  \n",
      " 43  미팅/채팅             97568 non-null  int64  \n",
      " 44  게임                97568 non-null  int64  \n",
      " 45  종교                97568 non-null  int64  \n",
      " 46  쇼핑                97568 non-null  int64  \n",
      " 47  봉사활동              97568 non-null  int64  \n",
      " 48  식도락               97568 non-null  int64  \n",
      " 49  청춘사업              97568 non-null  int64  \n",
      " 50  패션                97568 non-null  int64  \n",
      " 51  댄스                97568 non-null  int64  \n",
      " 52  등산                97568 non-null  int64  \n",
      " 53  tv/비디오            97568 non-null  int64  \n",
      " 54  라디오               97568 non-null  int64  \n",
      " 55  놀이동산              97568 non-null  int64  \n",
      " 56  여행                97568 non-null  int64  \n",
      " 57  요리                97568 non-null  int64  \n",
      " 58  낚시                97568 non-null  int64  \n",
      " 59  드라이브              97568 non-null  int64  \n",
      " 60  인테리어              97568 non-null  int64  \n",
      " 61  연극/영화             97568 non-null  int64  \n",
      " 62  미용                97568 non-null  int64  \n",
      " 63  정치                97568 non-null  int64  \n",
      " 64  음악                97568 non-null  int64  \n",
      " 65  사진/영상             97568 non-null  int64  \n",
      " 66  연예계               97568 non-null  int64  \n",
      " 67  독서/만화             97568 non-null  int64  \n",
      " 68  재테크               97568 non-null  int64  \n",
      " 69  av/홈시어터           97568 non-null  int64  \n",
      " 70  장기/바둑             97568 non-null  int64  \n",
      " 71  수다떨기              97568 non-null  int64  \n",
      " 72  컴퓨터/인터넷           97568 non-null  int64  \n",
      " 73  공연관람              97568 non-null  int64  \n",
      " 74  sns관리             97568 non-null  int64  \n",
      " 75  블로그관리             97568 non-null  int64  \n",
      " 76  골동품수집             97568 non-null  int64  \n",
      " 77  기타수집              97568 non-null  int64  \n",
      " 78  약초/난캐기            97568 non-null  int64  \n",
      " 79  악기연주              97568 non-null  int64  \n",
      " 80  수영                97568 non-null  int64  \n",
      " 81  골프                97568 non-null  int64  \n",
      " 82  볼링                97568 non-null  int64  \n",
      " 83  자전거               97568 non-null  int64  \n",
      " 84  오토바이              97568 non-null  int64  \n",
      " 85  자동차튜닝             97568 non-null  int64  \n",
      " 86  형제수               97568 non-null  int64  \n",
      " 87  자매수               97568 non-null  int64  \n",
      " 88  몇째                97568 non-null  int64  \n",
      "dtypes: float64(1), int64(58), object(30)\n",
      "memory usage: 67.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mate_conts\"]=data[\"mate_conts\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9 ? !]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=pd.read_csv(\"../data/thanks_yeobaya_2.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11097 entries, 0 to 11096\n",
      "Data columns (total 37 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   auto_no                11097 non-null  int64  \n",
      " 1   reg_slct               11097 non-null  object \n",
      " 2   reg_mem_no             11097 non-null  int64  \n",
      " 3   reg_name               0 non-null      float64\n",
      " 4   reg_title              11097 non-null  object \n",
      " 5   reg_sex                11041 non-null  object \n",
      " 6   reg_age                11097 non-null  int64  \n",
      " 7   reg_nick               11036 non-null  object \n",
      " 8   reg_photo              7321 non-null   object \n",
      " 9   reg_photo_cnt          11097 non-null  int64  \n",
      " 10  reg_loc                11034 non-null  object \n",
      " 11  reg_job_detail         11016 non-null  object \n",
      " 12  reg_join_date          11077 non-null  object \n",
      " 13  reg_job                11037 non-null  float64\n",
      " 14  reg_point              11097 non-null  int64  \n",
      " 15  reg_conts              11097 non-null  object \n",
      " 16  reg_date               11096 non-null  object \n",
      " 17  reg_exit_date          10978 non-null  object \n",
      " 18  photo_cnt              11097 non-null  int64  \n",
      " 19  cert_salary_photo_cnt  11097 non-null  int64  \n",
      " 20  cert_career_photo_cnt  11097 non-null  int64  \n",
      " 21  cert_car_photo_cnt     11097 non-null  int64  \n",
      " 22  cert_certfc_photo_cnt  11097 non-null  int64  \n",
      " 23  cert_job_photo_cnt     11097 non-null  int64  \n",
      " 24  cert_gif_data_cnt      11097 non-null  int64  \n",
      " 25  cert_voice_data_cnt    11097 non-null  int64  \n",
      " 26  cert_mov_data_cnt      11097 non-null  int64  \n",
      " 27  auth_cnt               11097 non-null  int64  \n",
      " 28  mate_conts             10739 non-null  object \n",
      " 29  family_conts           10939 non-null  object \n",
      " 30  hit_cnt                11097 non-null  int64  \n",
      " 31  hit_m_cnt              11097 non-null  int64  \n",
      " 32  hit_f_cnt              11097 non-null  int64  \n",
      " 33  hit_n_cnt              11097 non-null  int64  \n",
      " 34  prt_slct               11097 non-null  object \n",
      " 35  ins_date               11097 non-null  object \n",
      " 36  gift_yn                11097 non-null  object \n",
      "dtypes: float64(2), int64(19), object(16)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m.drop(data_m.loc[data_m[\"mate_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m[\"family_conts\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m.drop(data_m.loc[data_m[\"family_conts\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10730 entries, 0 to 11090\n",
      "Data columns (total 37 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   auto_no                10730 non-null  int64  \n",
      " 1   reg_slct               10730 non-null  object \n",
      " 2   reg_mem_no             10730 non-null  int64  \n",
      " 3   reg_name               0 non-null      float64\n",
      " 4   reg_title              10730 non-null  object \n",
      " 5   reg_sex                10729 non-null  object \n",
      " 6   reg_age                10730 non-null  int64  \n",
      " 7   reg_nick               10730 non-null  object \n",
      " 8   reg_photo              7198 non-null   object \n",
      " 9   reg_photo_cnt          10730 non-null  int64  \n",
      " 10  reg_loc                10729 non-null  object \n",
      " 11  reg_job_detail         10727 non-null  object \n",
      " 12  reg_join_date          10730 non-null  object \n",
      " 13  reg_job                10730 non-null  float64\n",
      " 14  reg_point              10730 non-null  int64  \n",
      " 15  reg_conts              10730 non-null  object \n",
      " 16  reg_date               10729 non-null  object \n",
      " 17  reg_exit_date          10730 non-null  object \n",
      " 18  photo_cnt              10730 non-null  int64  \n",
      " 19  cert_salary_photo_cnt  10730 non-null  int64  \n",
      " 20  cert_career_photo_cnt  10730 non-null  int64  \n",
      " 21  cert_car_photo_cnt     10730 non-null  int64  \n",
      " 22  cert_certfc_photo_cnt  10730 non-null  int64  \n",
      " 23  cert_job_photo_cnt     10730 non-null  int64  \n",
      " 24  cert_gif_data_cnt      10730 non-null  int64  \n",
      " 25  cert_voice_data_cnt    10730 non-null  int64  \n",
      " 26  cert_mov_data_cnt      10730 non-null  int64  \n",
      " 27  auth_cnt               10730 non-null  int64  \n",
      " 28  mate_conts             10730 non-null  object \n",
      " 29  family_conts           10730 non-null  object \n",
      " 30  hit_cnt                10730 non-null  int64  \n",
      " 31  hit_m_cnt              10730 non-null  int64  \n",
      " 32  hit_f_cnt              10730 non-null  int64  \n",
      " 33  hit_n_cnt              10730 non-null  int64  \n",
      " 34  prt_slct               10730 non-null  object \n",
      " 35  ins_date               10730 non-null  object \n",
      " 36  gift_yn                10730 non-null  object \n",
      "dtypes: float64(2), int64(19), object(16)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m[\"mate_conts\"]=data_m[\"mate_conts\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9 ? !]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=data.loc[:10730,['mate_conts','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mate_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>화려한 돌씽입니다  맘 맞는분 만나서 남은 반생 같이하고 싶습니다   여행가는것 좋...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>????????????????????????좋은사람 좋은인연 기다립니다 그럼 오늘하...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>반갑습니다  새로운 인연 기다립니다  같은 생각으로 같은 길을 갔으면 합니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여보야는 2015년에 런칭했으며 2020년도에는 4만쌍의 성혼을 이루도록 더 많은 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>안녕 하세요   도시생활  정리하고  조그마한  읍내에서  레포츠샵  운영하고  있...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>인연이돠고싶습니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>산다는게 꼭 법칙만 가지고 되는게 아니라 인내와 노력성실과 운이만나야 되는걸 느끼네...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>현실에서 누군가를 소개 받는게 쉽지 않은 나이입니다  그래서 이 어플에 기대어 자기...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10730</th>\n",
       "      <td>안녕하세요  39살의 미혼남입니다  외모는 제 눈에만 예뻤으면 싶은 재혼 아닌분만 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              mate_conts  label\n",
       "0      화려한 돌씽입니다  맘 맞는분 만나서 남은 반생 같이하고 싶습니다   여행가는것 좋...      0\n",
       "1      삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...      0\n",
       "2      ????????????????????????좋은사람 좋은인연 기다립니다 그럼 오늘하...      0\n",
       "3            반갑습니다  새로운 인연 기다립니다  같은 생각으로 같은 길을 갔으면 합니다       0\n",
       "4      여보야는 2015년에 런칭했으며 2020년도에는 4만쌍의 성혼을 이루도록 더 많은 ...      0\n",
       "...                                                  ...    ...\n",
       "10726  안녕 하세요   도시생활  정리하고  조그마한  읍내에서  레포츠샵  운영하고  있...      0\n",
       "10727                   인연이돠고싶습니다                             0\n",
       "10728  산다는게 꼭 법칙만 가지고 되는게 아니라 인내와 노력성실과 운이만나야 되는걸 느끼네...      0\n",
       "10729  현실에서 누군가를 소개 받는게 쉽지 않은 나이입니다  그래서 이 어플에 기대어 자기...      0\n",
       "10730  안녕하세요  39살의 미혼남입니다  외모는 제 눈에만 예뻤으면 싶은 재혼 아닌분만 ...      0\n",
       "\n",
       "[10731 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=data_m.loc[:,['mate_conts','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mate_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세상사 혼자가는길은 잠시 편할수는 있겠지만  잠시뿐  내가 가는길에 그대와함께라면 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>안녕하세요 진솔하게 만나고 싶습니다   잘부탁드려요 ㅎ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사별하고 육년이 지났네요  이제마음의 상처 뒤로하고밝고 따뜻하며 취미생활 운동 같이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서로배려해주고 거짓없는 이성친구 찾고있어요   딸아이가 어느덧 결혼할 나이가 되다보...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>딸 아들을 둔 엄마입니다  자식은 품안에 있을때만이 자식이란 말을절감합니다  각자 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>안녕하세요  가식없고  진실된 비흡연 처자입니다  좋은 배필만나서 부모님 공경하며 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>대전 세종 충남 거주  퇴근후 자주 볼수 있는분 찾습니다 영화보기  맛집탐방  운...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>안녕하세요?저는 긍정적인 사고방식과명랑쾌활하며계획적인 일상생활을하며 성실히 살아갸고...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>연하의 차분하고 다저다감한 스타일을 선호합니다  기독교인이며 여행과 독서  그리고 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>반갑습니다  당장 결혼생각보다 호기심에 가입하게 되었습니다  모두 좋은 인연 만나셔...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10730 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              mate_conts  label\n",
       "0      세상사 혼자가는길은 잠시 편할수는 있겠지만  잠시뿐  내가 가는길에 그대와함께라면 ...      1\n",
       "1                         안녕하세요 진솔하게 만나고 싶습니다   잘부탁드려요 ㅎ      1\n",
       "2      사별하고 육년이 지났네요  이제마음의 상처 뒤로하고밝고 따뜻하며 취미생활 운동 같이...      1\n",
       "3      서로배려해주고 거짓없는 이성친구 찾고있어요   딸아이가 어느덧 결혼할 나이가 되다보...      1\n",
       "4      딸 아들을 둔 엄마입니다  자식은 품안에 있을때만이 자식이란 말을절감합니다  각자 ...      1\n",
       "...                                                  ...    ...\n",
       "11043  안녕하세요  가식없고  진실된 비흡연 처자입니다  좋은 배필만나서 부모님 공경하며 ...      1\n",
       "11085   대전 세종 충남 거주  퇴근후 자주 볼수 있는분 찾습니다 영화보기  맛집탐방  운...      1\n",
       "11088  안녕하세요?저는 긍정적인 사고방식과명랑쾌활하며계획적인 일상생활을하며 성실히 살아갸고...      1\n",
       "11089  연하의 차분하고 다저다감한 스타일을 선호합니다  기독교인이며 여행과 독서  그리고 ...      1\n",
       "11090  반갑습니다  당장 결혼생각보다 호기심에 가입하게 되었습니다  모두 좋은 인연 만나셔...      1\n",
       "\n",
       "[10730 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.concat([train1,train2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mate_conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>화려한 돌씽입니다  맘 맞는분 만나서 남은 반생 같이하고 싶습니다   여행가는것 좋...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>????????????????????????좋은사람 좋은인연 기다립니다 그럼 오늘하...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>반갑습니다  새로운 인연 기다립니다  같은 생각으로 같은 길을 갔으면 합니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여보야는 2015년에 런칭했으며 2020년도에는 4만쌍의 성혼을 이루도록 더 많은 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>안녕하세요  가식없고  진실된 비흡연 처자입니다  좋은 배필만나서 부모님 공경하며 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>대전 세종 충남 거주  퇴근후 자주 볼수 있는분 찾습니다 영화보기  맛집탐방  운...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>안녕하세요?저는 긍정적인 사고방식과명랑쾌활하며계획적인 일상생활을하며 성실히 살아갸고...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>연하의 차분하고 다저다감한 스타일을 선호합니다  기독교인이며 여행과 독서  그리고 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>반갑습니다  당장 결혼생각보다 호기심에 가입하게 되었습니다  모두 좋은 인연 만나셔...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              mate_conts  label\n",
       "0      화려한 돌씽입니다  맘 맞는분 만나서 남은 반생 같이하고 싶습니다   여행가는것 좋...      0\n",
       "1      삼남매이며 형제간에우애하고 화목한가정에서 자랐습니다 앞으로도 좋은가정을 이뤄나아가고...      0\n",
       "2      ????????????????????????좋은사람 좋은인연 기다립니다 그럼 오늘하...      0\n",
       "3            반갑습니다  새로운 인연 기다립니다  같은 생각으로 같은 길을 갔으면 합니다       0\n",
       "4      여보야는 2015년에 런칭했으며 2020년도에는 4만쌍의 성혼을 이루도록 더 많은 ...      0\n",
       "...                                                  ...    ...\n",
       "11043  안녕하세요  가식없고  진실된 비흡연 처자입니다  좋은 배필만나서 부모님 공경하며 ...      1\n",
       "11085   대전 세종 충남 거주  퇴근후 자주 볼수 있는분 찾습니다 영화보기  맛집탐방  운...      1\n",
       "11088  안녕하세요?저는 긍정적인 사고방식과명랑쾌활하며계획적인 일상생활을하며 성실히 살아갸고...      1\n",
       "11089  연하의 차분하고 다저다감한 스타일을 선호합니다  기독교인이며 여행과 독서  그리고 ...      1\n",
       "11090  반갑습니다  당장 결혼생각보다 호기심에 가입하게 되었습니다  모두 좋은 인연 만나셔...      1\n",
       "\n",
       "[21461 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_data[\"mate_conts\"]\n",
    "y=train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0      1  0\n",
       "1      1  0\n",
       "2      1  0\n",
       "3      1  0\n",
       "4      1  0\n",
       "...   .. ..\n",
       "21456  0  1\n",
       "21457  0  1\n",
       "21458  0  1\n",
       "21459  0  1\n",
       "21460  0  1\n",
       "\n",
       "[21461 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9683     안녕하세요     결혼하고 늘 한결같이  챙겨주고싶은  인연을 만났으면 합니다   ...\n",
       "6521     저는 평범하고 근면성실하며 근검절약하는 사람입니다  그런 저와 같이 알뜰살뜰 하게 ...\n",
       "16074    1  애 딸린 홀아비 13년차  재혼 힘든거 알고있음  맘 비움   2  그냥 저냥...\n",
       "14920    여러분들은 실패의 원인을 알고 있습니까? 과연 나는 잘했을까요? 자신의 단점의 팩트...\n",
       "18818    좋은연분기대합니다 말보다 행동 진실 믿음 배려 존중 두손꼭잡고 살수있도록 나의반쪽분...\n",
       "                               ...                        \n",
       "6400     안녕하세요  ! 저는 이렇답니다  성격은다정하고 유 하며 공감능력이 좋고 생각이 깨...\n",
       "15288    안녕하세요? 반갑습니다   좋은사람 편한사람 함께 공유할수있는분  만나고싶네요  남...\n",
       "11513    수출입 콘테이너 를 같이 타고 다니면서 과일도 먹여주고사랑할 배우자를 구합니다 종손...\n",
       "1688     저는 그냥 평범한사람입니다 조용하고 술 담배   완전체 못합니다 또래 편한친구 찾습...\n",
       "5994     아름다운  꽃길이 눈부시게 마음이 설레듯  같이 바라보면서   당신과 함께 있고 싶...\n",
       "Name: mate_conts, Length: 16095, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15450    저는 첫인상은 모두들 까칠할거같다  술잘마실거같다  등등  얘기하지만 술은 전  혀...\n",
       "2400     전직 호텔리어   현제 초보농사꾼 ??? 입니다 농사짓는다고하면 보통 일은많고 쉬는...\n",
       "20193    안녕하세요   못 생긴 평범한 남자입니다  그리고 한번 실패로 인해서 서로 아픔을 ...\n",
       "15896    혼자 지낸지 11년 됐네요  이혼후 사업실패하고 다시  재기하고 자리 매김 하느라 ...\n",
       "10356    만남이 절실하지만 진실된 만남만을 원합니다  현재 뉴에이지 피아니스트로 활동하면서 ...\n",
       "                               ...                        \n",
       "14288            자녀는아들딸둘다출가하고저혼자입니다혼자돼다보니왜롭네요좋은인연만낫으면좋겠읍니다\n",
       "16005             저는 4살딸키우고 있구요 착하고 듬직한남자였음좋겠어요 제딸도 이뻐해주고요\n",
       "19134    나이는 숫자에 불과하다생각합니다   시대를 쫓아가며 젊게살고있고 여행  운동 등 활...\n",
       "17207    혼기 놓친 노총각입니다     현재 하는일은 기술직이구요 정년없이 계속일할수 있어 ...\n",
       "16077    맘통하구 서로를이해하구 인정해줄수 있는     그렇게 같은취미생활할수있는     거...\n",
       "Name: mate_conts, Length: 5366, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_txt=[]\n",
    "for sentence in X_train:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence)#토큰화\n",
    "    X_train_txt.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_txt=[]\n",
    "for sentence in X_test:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence)#토큰화\n",
    "    X_test_txt.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['안녕하세요', '결혼', '하고', '늘', '한결같이', '챙겨주고싶은', '인연', '을', '만났으면', '합니다', '울산', '에서', '안정', '적', '인', '직장', '생활', '하고', '있습니다', '좋은', '인연', '기다리겠습니다'], ['저', '는', '평범하고', '근면', '성실하며', '근', '검', '절약', '하', '는', '사람', '입니다', '그런', '저', '와', '같이', '알뜰살뜰', '하게', '가정', '을', '이루어주실', '분', '을', '찾습니다'], ['1', '애', '딸린', '홀아비', '13년', '차', '재혼', '힘든거', '알고있음', '맘', '비움', '2', '그냥', '저', '냥', '먹구', '살', '만큼', '있구', '벌구', '경제', '적', '안정', '3', '맘', '맞는', '여자친구', '있음', '좋겠음', '집', '가까이', '그러다', '더', '좋아지면', '결혼', '까지', '갈', '수', '있음', '4', '본인', '이', '평범', '하다는', '분', '보다', '자존감', '높으신', '분', '이', '좋음', '남', '들', '보기', '에', '아니더라도', '본인', '스스로', '예쁨', '섹시', '하다고', '생각', '하시는', '분', '그런', '분', '멋짐', '5', '!', '전', '그닥', '잘생기지도', '않았고', '키도', '큰', '편', '아니니', '참고', '신체', '는', '건강함', '남자', '로서', '이상', '없음', '남자', '처럼', '생김', '육아', '살림', '요리', '잘', '함', '나름', '똑똑', '사회생활', '잘', '함']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_txt[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['저', '는', '첫인상', '은', '모두', '들', '까칠할거', '같다', '술', '잘', '마실거', '같다', '등등', '얘기', '하지만', '술', '은', '전', '혀', '입', '에도', '못', '대', '고', '사교성', '있고', '친해지면', '친', '근', '감', '있게', '상대', '를', '불편하게하는', '스타일', '은', '아닙니다', '부탁드립니다', '아무나', '찔러', '보는', '분', '들', '정중히', '사절', '합니다', '저', '는', '그러려고', '가입', '했던건', '절대', '아니', '라서', '요', '그리고', '저', '는', '아이', '가', '있기에', '제', '상황', '모두', '고려', '해서', '진실성', '있게', '다가와주시는', '분', '을', '원해요', '저', '는', '저', '보다는', '아이', '를', '먼저', '생각', '해주시고', '힘든', '일이', '라는', '건', '알', '지만', '진심', '으로', '아이', '를', '대', '할줄아는', '분이면', '좋겠네요', '또', '하나', '경제', '적', '능력', '도', '있는', '분이면', '더', '좋겠져', '?'], ['전직', '호텔리어', '현', '제', '초보', '농사', '꾼', '???', '입니다', '농사짓는다고', '하면', '보통', '일', '은', '많고', '쉬는', '날', '없이', '바쁘다고', '생각', '하시겠지만', '그', '반대', '로', '쉬는', '날', '도', '많으며', '연봉', '도', '제', '또래', '보다는', '1', '5', '배는', '많이', '번다', '고', '자부', '합니다', '흡연', '은', '하지만', '전자담배', '를', '피기', '때문', '에', '담배', '냄새', '는', '전혀', '안나', '며', '초혼', '재혼', '은', '그닥', '중요하게', '생각', '하지', '않습니다', '같이', '손잡고', '산책', '도', '다니고', '즐겁게', '여행', '도', '다니실', '분', '단', '한', '분만', '기다립니다'], ['안녕하세요', '못', '생긴', '평범한', '남자', '입니다', '그리고', '한번', '실패', '로', '인해서', '서로', '아픔', '을', '보듬어주면서', '서로', '웃으며', '지내고', '싶고', '여행', '도', '같이', '다니고', '하면', '좋겠습니다', '또한', '행복한', '삶', '을', '저', '와', '함께', '하실', '분', '을', '찾습니다', '그리고', '저', '는', '아이', '가', '없습니다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_txt[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame([tokenizer.word_counts.keys(),\n",
    "                       tokenizer.word_counts.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = word_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.columns=['word','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>을</td>\n",
       "      <td>18218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>이</td>\n",
       "      <td>14440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>분</td>\n",
       "      <td>9436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>에</td>\n",
       "      <td>7919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>은</td>\n",
       "      <td>7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>봤기</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21517</th>\n",
       "      <td>먹어는</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516</th>\n",
       "      <td>징그러운것</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21515</th>\n",
       "      <td>있는것과</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38327</th>\n",
       "      <td>화려함이나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38328 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count\n",
       "7          을  18218\n",
       "75         이  14440\n",
       "38         분   9436\n",
       "85         에   7919\n",
       "122        은   7733\n",
       "...      ...    ...\n",
       "21518     봤기      1\n",
       "21517    먹어는      1\n",
       "21516  징그러운것      1\n",
       "21515   있는것과      1\n",
       "38327  화려함이나      1\n",
       "\n",
       "[38328 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=38330\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train_txt)\n",
    "X_train=tokenizer.texts_to_sequences(X_train_txt)\n",
    "X_test=tokenizer.texts_to_sequences(X_test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 50, 9, 309, 3411, 12170, 15, 1, 250, 16, 895, 25, 316, 21, 56, 137, 63, 9, 44, 7, 15, 847], [14, 6, 800, 1225, 1545, 1702, 8167, 7144, 75, 6, 8, 10, 82, 14, 53, 31, 8168, 148, 116, 1, 17377, 3, 1, 199], [266, 385, 7145, 9698, 2314, 343, 111, 5388, 12171, 159, 12172, 230, 211, 14, 1546, 3567, 35, 554, 2431, 12173, 373, 21, 316, 394, 159, 215, 1563, 651, 5842, 297, 1158, 1865, 87, 7146, 50, 103, 471, 79, 651, 622, 739, 2, 1547, 5843, 3, 110, 2067, 9699, 3, 2, 3739, 162, 37, 534, 4, 2023, 739, 1274, 12174, 5389, 3568, 23, 198, 3, 82, 3, 12175, 706, 59, 89, 4663, 3039, 3740, 3926, 405, 362, 5844, 472, 782, 6, 5845, 61, 1371, 283, 1138, 61, 85, 9700, 4134, 1259, 294, 27, 420, 295, 4381, 1517, 27, 420]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 6, 1490, 5, 231, 37, 4775, 121, 27, 4775, 1196, 381, 247, 121, 5, 89, 11262, 1905, 718, 93, 150, 20, 3236, 112, 915, 2136, 1702, 1222, 705, 161, 12, 217, 5, 801, 322, 1896, 1027, 665, 3, 37, 609, 169, 16, 14, 6, 11300, 67, 22041, 652, 1516, 1239, 34, 134, 14, 6, 122, 11, 1961, 40, 1334, 231, 3617, 156, 2388, 705, 21164, 3, 1, 551, 14, 6, 14, 182, 122, 12, 289, 23, 6088, 826, 460, 449, 844, 155, 302, 140, 17, 122, 12, 150, 1172, 131, 171, 515, 216, 373, 21, 436, 13, 24, 131, 87, 43], [3611, 11057, 735, 40, 4954, 1568, 4123, 3761, 10, 328, 935, 52, 5, 290, 1349, 243, 126, 8283, 23, 11179, 100, 4816, 39, 1349, 243, 13, 2364, 1290, 13, 40, 3017, 182, 266, 706, 18482, 81, 20, 1184, 16, 246, 5, 247, 5645, 12, 12805, 440, 4, 142, 2127, 6, 908, 4292, 163, 384, 111, 5, 4663, 1366, 23, 191, 277, 31, 303, 387, 13, 208, 238, 45, 13, 2962, 3, 432, 28, 135, 273]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16074</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14920</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18818</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16095 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "9683   1  0\n",
       "6521   1  0\n",
       "16074  0  1\n",
       "14920  0  1\n",
       "18818  0  1\n",
       "...   .. ..\n",
       "6400   1  0\n",
       "15288  0  1\n",
       "11513  0  1\n",
       "1688   1  0\n",
       "5994   1  0\n",
       "\n",
       "[16095 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20193</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15896</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17207</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "15450  0  1\n",
       "2400   1  0\n",
       "20193  0  1\n",
       "15896  0  1\n",
       "10356  1  0\n",
       "...   .. ..\n",
       "14288  0  1\n",
       "16005  0  1\n",
       "19134  0  1\n",
       "17207  0  1\n",
       "16077  0  1\n",
       "\n",
       "[5366 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_len = [len(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1954., 4733., 3210., 1993., 1367.,  964.,  847.,  826.,  186.,\n",
       "          15.]),\n",
       " array([  0. ,  14.2,  28.4,  42.6,  56.8,  71. ,  85.2,  99.4, 113.6,\n",
       "        127.8, 142. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=130\n",
    "X_train_pad=pad_sequences(X_train,maxlen=max_len)\n",
    "X_test_pad=pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     7,    15,   847],\n",
       "       [    0,     0,     0, ...,     3,     1,   199],\n",
       "       [    0,     0,     0, ...,  1517,    27,   420],\n",
       "       ...,\n",
       "       [    0,     0,     0, ..., 38325,   818,  1697],\n",
       "       [    0,     0,     0, ...,    98,   200, 16791],\n",
       "       [    0,     0,     0, ...,   208,    44,    43]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../model/text_model-{epoch:02d}-{val_accuracy:.4f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(filename,\n",
    "                     monitor='val_accuracy',\n",
    "                     verbose=1,\n",
    "                     save_best_only=True)\n",
    "es = EarlyStopping(monitor=\"val_accuracy\",patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A9BDA2F378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A9BDA2F378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.5923WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A98A1DD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A98A1DD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61554, saving model to ../model\\text_model-01-0.6155.hdf5\n",
      "1610/1610 [==============================] - 96s 59ms/step - loss: 0.6678 - accuracy: 0.5923 - val_loss: 0.6511 - val_accuracy: 0.6155\n",
      "Epoch 2/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.7399\n",
      "Epoch 00002: val_accuracy improved from 0.61554 to 0.63343, saving model to ../model\\text_model-02-0.6334.hdf5\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.5353 - accuracy: 0.7399 - val_loss: 0.6437 - val_accuracy: 0.6334\n",
      "Epoch 3/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8473\n",
      "Epoch 00003: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.3567 - accuracy: 0.8473 - val_loss: 0.7702 - val_accuracy: 0.6332\n",
      "Epoch 4/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9109\n",
      "Epoch 00004: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 99s 61ms/step - loss: 0.2250 - accuracy: 0.9109 - val_loss: 0.9093 - val_accuracy: 0.6114\n",
      "Epoch 5/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9450\n",
      "Epoch 00005: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.1434 - accuracy: 0.9450 - val_loss: 1.5406 - val_accuracy: 0.6137\n",
      "Epoch 6/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9688\n",
      "Epoch 00006: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 97s 60ms/step - loss: 0.0852 - accuracy: 0.9688 - val_loss: 1.6228 - val_accuracy: 0.6103\n",
      "Epoch 7/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9766\n",
      "Epoch 00007: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 97s 60ms/step - loss: 0.0656 - accuracy: 0.9766 - val_loss: 1.4476 - val_accuracy: 0.6021\n",
      "Epoch 8/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9820\n",
      "Epoch 00008: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.0556 - accuracy: 0.9820 - val_loss: 1.8137 - val_accuracy: 0.6111\n",
      "Epoch 9/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9855\n",
      "Epoch 00009: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 59ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 1.7972 - val_accuracy: 0.6049\n",
      "Epoch 10/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9899\n",
      "Epoch 00010: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 1.7984 - val_accuracy: 0.6081\n",
      "Epoch 11/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9932\n",
      "Epoch 00011: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 2.4256 - val_accuracy: 0.6077\n",
      "Epoch 12/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 00012: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 2.1571 - val_accuracy: 0.5975\n",
      "Epoch 13/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 00013: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 2.6903 - val_accuracy: 0.6034\n",
      "Epoch 14/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9960\n",
      "Epoch 00014: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 2.5144 - val_accuracy: 0.5904\n",
      "Epoch 15/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 00015: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 2.9266 - val_accuracy: 0.6073\n",
      "Epoch 16/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 00016: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 2.8821 - val_accuracy: 0.5952\n",
      "Epoch 17/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 00017: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 2.7231 - val_accuracy: 0.6029\n",
      "Epoch 18/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00018: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.1463 - val_accuracy: 0.6014\n",
      "Epoch 19/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 00019: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 95s 59ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 2.6033 - val_accuracy: 0.5947\n",
      "Epoch 20/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 00020: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 2.5042 - val_accuracy: 0.5986\n",
      "Epoch 21/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 00021: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 59ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 2.6953 - val_accuracy: 0.5945\n",
      "Epoch 22/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00022: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 3.3107 - val_accuracy: 0.6001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 00023: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 3.0711 - val_accuracy: 0.6025\n",
      "Epoch 24/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00024: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 3.0333 - val_accuracy: 0.6049\n",
      "Epoch 25/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00025: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 3.3652 - val_accuracy: 0.5967\n",
      "Epoch 26/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00026: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 3.1624 - val_accuracy: 0.6038\n",
      "Epoch 27/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 00027: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 3.3573 - val_accuracy: 0.5988\n",
      "Epoch 28/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 00028: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 2.7920 - val_accuracy: 0.6051\n",
      "Epoch 29/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00029: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 3.3789 - val_accuracy: 0.5978\n",
      "Epoch 30/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00030: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 2.8874 - val_accuracy: 0.6018\n",
      "Epoch 31/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00031: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.3293 - val_accuracy: 0.6051\n",
      "Epoch 32/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 00032: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 3.4914 - val_accuracy: 0.6055\n",
      "Epoch 33/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00033: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 98s 61ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 3.9040 - val_accuracy: 0.6042\n",
      "Epoch 34/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 00034: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 59ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 4.4863 - val_accuracy: 0.5889\n",
      "Epoch 35/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 00035: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 3.2328 - val_accuracy: 0.6036\n",
      "Epoch 36/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9982\n",
      "Epoch 00036: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 2.7671 - val_accuracy: 0.6016\n",
      "Epoch 37/1000\n",
      "1609/1610 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9985\n",
      "Epoch 00037: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 3.0700 - val_accuracy: 0.6090\n",
      "Epoch 38/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00038: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 3.9539 - val_accuracy: 0.6044\n",
      "Epoch 39/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00039: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 3.1603 - val_accuracy: 0.6059\n",
      "Epoch 40/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00040: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 2.9860 - val_accuracy: 0.6027\n",
      "Epoch 41/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 00041: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 3.1333 - val_accuracy: 0.6073\n",
      "Epoch 42/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00042: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.5105 - val_accuracy: 0.6049\n",
      "Epoch 43/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 00043: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 3.7333 - val_accuracy: 0.6006\n",
      "Epoch 44/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00044: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 95s 59ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 2.8655 - val_accuracy: 0.5969\n",
      "Epoch 45/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9983\n",
      "Epoch 00045: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 2.4289 - val_accuracy: 0.5971\n",
      "Epoch 46/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9988\n",
      "Epoch 00046: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 3.3234 - val_accuracy: 0.5991\n",
      "Epoch 47/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 00047: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 3.2495 - val_accuracy: 0.6016\n",
      "Epoch 48/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 00048: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 3.1543 - val_accuracy: 0.5963\n",
      "Epoch 49/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 00049: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 3.6757 - val_accuracy: 0.6038\n",
      "Epoch 50/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00050: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 3.5616 - val_accuracy: 0.6038\n",
      "Epoch 51/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 00051: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 3.5483 - val_accuracy: 0.5995\n",
      "Epoch 52/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00052: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 2.8885 - val_accuracy: 0.6029\n",
      "Epoch 53/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9992\n",
      "Epoch 00053: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 3.8111 - val_accuracy: 0.6034\n",
      "Epoch 54/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 00054: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 4.3699 - val_accuracy: 0.6060\n",
      "Epoch 55/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 00055: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 3.9908 - val_accuracy: 0.6055\n",
      "Epoch 56/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00056: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 3.2188 - val_accuracy: 0.6072\n",
      "Epoch 57/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00057: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 3.6200 - val_accuracy: 0.6045\n",
      "Epoch 58/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00058: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 3.6086 - val_accuracy: 0.6077\n",
      "Epoch 59/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 6.6213e-04 - accuracy: 0.9998\n",
      "Epoch 00059: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 6.6213e-04 - accuracy: 0.9998 - val_loss: 4.0334 - val_accuracy: 0.6062\n",
      "Epoch 60/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 8.6768e-04 - accuracy: 0.9993\n",
      "Epoch 00060: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 8.6768e-04 - accuracy: 0.9993 - val_loss: 4.2841 - val_accuracy: 0.6100\n",
      "Epoch 61/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 00061: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 4.6984 - val_accuracy: 0.6085\n",
      "Epoch 62/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 6.8768e-04 - accuracy: 0.9994\n",
      "Epoch 00062: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 6.8768e-04 - accuracy: 0.9994 - val_loss: 5.0140 - val_accuracy: 0.6040\n",
      "Epoch 63/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 00063: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 5.3922 - val_accuracy: 0.6057\n",
      "Epoch 64/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00064: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 4.0592 - val_accuracy: 0.6051\n",
      "Epoch 65/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9979\n",
      "Epoch 00065: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 2.7424 - val_accuracy: 0.6101\n",
      "Epoch 66/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9969\n",
      "Epoch 00066: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 92s 57ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 2.9266 - val_accuracy: 0.6064\n",
      "Epoch 67/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9983\n",
      "Epoch 00067: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 92s 57ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 2.9701 - val_accuracy: 0.6053\n",
      "Epoch 68/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9988\n",
      "Epoch 00068: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 95s 59ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 3.2294 - val_accuracy: 0.6027\n",
      "Epoch 69/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 00069: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 95s 59ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 3.3444 - val_accuracy: 0.6027\n",
      "Epoch 70/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 00070: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 92s 57ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 3.3695 - val_accuracy: 0.6073\n",
      "Epoch 71/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 00071: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 93s 58ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 3.5148 - val_accuracy: 0.6070\n",
      "Epoch 72/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00072: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 3.5262 - val_accuracy: 0.6034\n",
      "Epoch 73/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 00073: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 3.6735 - val_accuracy: 0.6064\n",
      "Epoch 74/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00074: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 96s 60ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 3.0602 - val_accuracy: 0.6044\n",
      "Epoch 75/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 00075: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 3.4210 - val_accuracy: 0.6034\n",
      "Epoch 76/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00076: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 3.6786 - val_accuracy: 0.6100\n",
      "Epoch 77/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00077: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 3.6758 - val_accuracy: 0.5909\n",
      "Epoch 78/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00078: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 3.5759 - val_accuracy: 0.5990\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 00079: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 4.2708 - val_accuracy: 0.6083\n",
      "Epoch 80/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 00080: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 4.6463 - val_accuracy: 0.6029\n",
      "Epoch 81/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 00081: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 4.2379 - val_accuracy: 0.6131\n",
      "Epoch 82/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00082: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 5.2070 - val_accuracy: 0.6100\n",
      "Epoch 83/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9988\n",
      "Epoch 00083: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 3.8892 - val_accuracy: 0.6092\n",
      "Epoch 84/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00084: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 4.3016 - val_accuracy: 0.6055\n",
      "Epoch 85/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 00085: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 4.1579 - val_accuracy: 0.6109\n",
      "Epoch 86/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 00086: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 3.9905 - val_accuracy: 0.6148\n",
      "Epoch 87/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00087: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 3.4101 - val_accuracy: 0.6105\n",
      "Epoch 88/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\n",
      "Epoch 00088: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 3.6394 - val_accuracy: 0.6105\n",
      "Epoch 89/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00089: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 4.1332 - val_accuracy: 0.6120\n",
      "Epoch 90/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 00090: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 3.5371 - val_accuracy: 0.6148\n",
      "Epoch 91/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 6.4583e-04 - accuracy: 0.9998\n",
      "Epoch 00091: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 6.4583e-04 - accuracy: 0.9998 - val_loss: 4.7192 - val_accuracy: 0.6109\n",
      "Epoch 92/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 8.2740e-04 - accuracy: 0.9993\n",
      "Epoch 00092: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 8.2740e-04 - accuracy: 0.9993 - val_loss: 5.2017 - val_accuracy: 0.6094\n",
      "Epoch 93/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 6.8535e-04 - accuracy: 0.9996\n",
      "Epoch 00093: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 6.8535e-04 - accuracy: 0.9996 - val_loss: 5.4432 - val_accuracy: 0.6092\n",
      "Epoch 94/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 00094: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 4.6391 - val_accuracy: 0.6079\n",
      "Epoch 95/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9992\n",
      "Epoch 00095: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 3.9075 - val_accuracy: 0.5999\n",
      "Epoch 96/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 00096: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 3.6900 - val_accuracy: 0.5977\n",
      "Epoch 97/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9988\n",
      "Epoch 00097: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 2.8935 - val_accuracy: 0.5995\n",
      "Epoch 98/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 00098: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 3.1802 - val_accuracy: 0.6059\n",
      "Epoch 99/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 00099: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 3.8851 - val_accuracy: 0.6098\n",
      "Epoch 100/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 00100: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 4.2291 - val_accuracy: 0.6142\n",
      "Epoch 101/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00101: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 4.2495 - val_accuracy: 0.5975\n",
      "Epoch 102/1000\n",
      "1610/1610 [==============================] - ETA: 0s - loss: 8.6510e-04 - accuracy: 0.9994\n",
      "Epoch 00102: val_accuracy did not improve from 0.63343\n",
      "1610/1610 [==============================] - 94s 58ms/step - loss: 8.6510e-04 - accuracy: 0.9994 - val_loss: 4.8440 - val_accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(max_words,100))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history=model.fit(X_train_pad,y_train,epochs=1000,batch_size=10,\n",
    "                  validation_data=(X_test_pad,y_test), callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    sentence_before=[]\n",
    "    sentence_before.append(sent)\n",
    "    sent_txt=[]\n",
    "    for sentence in sentence_before:\n",
    "        temp_X=[]\n",
    "        temp_X=okt.morphs(sentence)\n",
    "        sent_txt.append(temp_X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_words=38330\n",
    "    tokenizer=Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(sent_txt)\n",
    "    f_data=tokenizer.texts_to_sequences(sent_txt)\n",
    "    max_len=130\n",
    "    data_pad=pad_sequences(f_data,maxlen=max_len)\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    p=model.predict(data_pad)[0][1]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=\"안녕하세요 잘부탁드립니다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001A8DA0C92F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001A8DA0C92F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21524209"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3=data.loc[:10730,['mate_conts','label']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
