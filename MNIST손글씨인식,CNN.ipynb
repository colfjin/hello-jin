{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 숫자 이미지 데이터(MNIST)를 이용해서 숫자를 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 문제정의\n",
    "- keras를 이용해서 손글씨 숫자 이미지 인식 신경망을 설계하고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\smt063\\anaconda3\\envs\\deep\\lib\\site-packages (1.6.3)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\smt063\\anaconda3\\envs\\deep\\lib\\site-packages (from astunparse==1.6.3) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\smt063\\anaconda3\\envs\\deep\\lib\\site-packages (from astunparse==1.6.3) (0.36.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"astunparse==1.6.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 데이터 전처리\n",
    "(4) 데이터 탐색/시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 크기\n",
    "train_images.shape,train_labels.shape\n",
    "#특성의 수 : 28*28=784개의 특성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159100e0160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANrklEQVR4nO3dXahc9bnH8d/PNxBbMDnZCSGGkx6TC0XQlkEEpb5hUS+MDTbUC40a2F4oWvXihGqoXih6SFsO+JpoMOdYo5FWzIX0VEw1FGPJKDkmMRz1SNSYYHYIWCuIJ/qci70s27jnPzsza16yn+8HhplZz6y9nj3Jb6+Z9V8zf0eEAEx/xwy6AQD9QdiBJAg7kARhB5Ig7EASx/VzY7NmzYoFCxb0c5NAKrt379aBAwc8Wa2rsNu+VNK/SzpW0uMRcX/p8QsWLFCz2exmkwAKGo1Gy1rHL+NtHyvpIUmXSTpd0tW2T+/05wHorW7es58t6b2IeD8ivpT0jKTF9bQFoG7dhH2epI8m3N9TLfsW26O2m7abY2NjXWwOQDe6CftkBwG+c+5tRKyOiEZENEZGRrrYHIBudBP2PZLmT7h/iqS93bUDoFe6CftWSYts/8D2CZJ+LmljPW0BqFvHQ28Rccj2zZL+S+NDb2sjYmdtnQGoVVfj7BHxoqQXa+oFQA9xuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfR1ymbgaHHRRRd1tf6mTZtq6qQ+7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZHSbbfdVqxv2bKlWL/22mvrbKcvugq77d2SPpP0laRDEdGooykA9atjz35hRByo4ecA6CHeswNJdBv2kPQn22/YHp3sAbZHbTdtN8fGxrrcHIBOdRv2cyPiR5Iuk3ST7R8f/oCIWB0RjYhojIyMdLk5AJ3qKuwRsbe63i/peUln19EUgPp1HHbbJ9n+/je3Jf1E0o66GgNQr26Oxs+R9Lztb37O0xHxx1q6AmqwYsWKlrVHH320uO7xxx9frF988cUd9TRIHYc9It6XdGaNvQDoIYbegCQIO5AEYQeSIOxAEoQdSIKPuGLaev3111vWvvzyy+K65513XrG+dOnSjnoaJPbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zT3ObNm4v1e++9t1hfv359sT5z5swj7qku7Xrbvn17y9rChQuL665ataqjnoYZe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9mludHTSWbn+4Z133inW33777WK93ee+e6ndOQIHDx5sWXv88ceL65555vT74mT27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs09yJJ55YrFdTbrf0xRdf1NnOEdm2bVux/uGHHxbrpd9tkL/XoLTds9tea3u/7R0Tls20/ZLtd6vrGb1tE0C3pvIy/klJlx62bIWklyNikaSXq/sAhljbsEfEZkmHn3e4WNK66vY6SVfW2xaAunV6gG5OROyTpOp6dqsH2h613bTdHBsb63BzALrV86PxEbE6IhoR0RgZGen15gC00GnYP7E9V5Kq6/31tQSgFzoN+0ZJy6rbyyS9UE87AHql7Ti77fWSLpA0y/YeSb+SdL+kDbaXS/pQ0s962STKVq5c2bK2Y8eOljVJOu2004r1Xn6u+/PPPy/WH3jgga7WP+ecc1rWrrrqquK601HbsEfE1S1KF9fcC4Ae4nRZIAnCDiRB2IEkCDuQBGEHkuAjrkeBjz76qFhfs2ZNy9pxx5X/iR966KFivZdnPd5+++3F+oYNG4r1efPmFeuvvfbaEfc0nbFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfAtu3by/WlyxZUqyXvu7rlltuKa57/vnnF+vdWrVqVcvak08+2dXPvvPOO7taPxv27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsNTh06FCx/tRTTxXrN9xwQ7EeEcV6aWriLVu2FNe97777ivU77rijWD948PBpAL/tueeea1lr93stW7asWL/xxhuLdXwbe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9ho888wzxfry5cuL9dI4+VQsWrSoZW3r1q3FddvVN27cWKx//PHHxfrevXtb1mbPnl1cd+3atcU6jkzbPbvttbb3294xYdndtj+2va26XN7bNgF0ayov45+UdOkky38bEWdVlxfrbQtA3dqGPSI2SyqfEwlg6HVzgO5m229VL/NntHqQ7VHbTdvN0nelAeitTsP+iKRTJZ0laZ+kX7d6YESsjohGRDR6OUkggLKOwh4Rn0TEVxHxtaQ1ks6uty0Adeso7LbnTrj7U0k7Wj0WwHBoO85ue72kCyTNsr1H0q8kXWD7LEkhabekaf/B4meffbZl7frrry+ue8IJJxTrJ598crH+9NNPF+szZrQ8ZNJ2DvRXX321WG83Dt/NZ+0PHDhQXHf+/PnF+iuvvFKsn3rqqcV6Nm3DHhFXT7L4iR70AqCHOF0WSIKwA0kQdiAJwg4kQdiBJPiI6xQ99thjLWvthojuuuuuYr3dV0l348EHHyzWR0dHi/V2X0Xdja+//rpYv/DCC4t1htaODHt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYpWrx4ccvakiVLiuu2G4fvpXYfI925c2dXP7/d12ifccYZHf/sU045peN18V3s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZp+jWW28ddAstffrppy1rGzZs6HhdSVq4cGGxvnTp0mIdw4M9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7NPDwww+3rD3yyCPFdefMmVOsb9q0qaOeMHza7tltz7f9Z9u7bO+0fWu1fKbtl2y/W123niQcwMBN5WX8IUl3RMRpks6RdJPt0yWtkPRyRCyS9HJ1H8CQahv2iNgXEW9Wtz+TtEvSPEmLJa2rHrZO0pU96hFADY7oAJ3tBZJ+KOmvkuZExD5p/A+CpNkt1hm13bTdHBsb67JdAJ2acthtf0/S7yX9IiL+NtX1ImJ1RDQiojEyMtJJjwBqMKWw2z5e40H/XUT8oVr8ie25VX2upP29aRFAHdoOvdm2pCck7YqI30wobZS0TNL91fULPekQ+uCDD4r1NWvWtKwdc0z573m7KZv5OufpYyrj7OdKukbSdtvbqmW/1HjIN9heLulDST/rSYcAatE27BHxF0luUb643nYA9AqnywJJEHYgCcIOJEHYgSQIO5AEH3E9ClxyySXFemkc/pprrimue88993TUE44+7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2Y8C1113XbG+cuXKlrUrrrii5m5wtGLPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCL6trFGoxHNZrNv2wOyaTQaajabk34bNHt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiibdhtz7f9Z9u7bO+0fWu1/G7bH9veVl0u7327ADo1lS+vOCTpjoh40/b3Jb1h+6Wq9tuIWNW79gDUZSrzs++TtK+6/ZntXZLm9boxAPU6ovfsthdI+qGkv1aLbrb9lu21tme0WGfUdtN2c2xsrLtuAXRsymG3/T1Jv5f0i4j4m6RHJJ0q6SyN7/l/Pdl6EbE6IhoR0RgZGem+YwAdmVLYbR+v8aD/LiL+IEkR8UlEfBURX0taI+ns3rUJoFtTORpvSU9I2hURv5mwfO6Eh/1U0o762wNQl6kcjT9X0jWSttveVi37paSrbZ8lKSTtlnRjD/oDUJOpHI3/i6TJPh/7Yv3tAOgVzqADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dcpm22PSfpgwqJZkg70rYEjM6y9DWtfEr11qs7e/jkiJv3+t76G/Tsbt5sR0RhYAwXD2tuw9iXRW6f61Rsv44EkCDuQxKDDvnrA2y8Z1t6GtS+J3jrVl94G+p4dQP8Mes8OoE8IO5DEQMJu+1Lb/2P7PdsrBtFDK7Z3295eTUPdHHAva23vt71jwrKZtl+y/W51PekcewPqbSim8S5MMz7Q527Q05/3/T277WMlvSPpEkl7JG2VdHVEvN3XRlqwvVtSIyIGfgKG7R9L+ruk/4iIM6pl/ybpYETcX/2hnBER/zokvd0t6e+Dnsa7mq1o7sRpxiVdKek6DfC5K/S1VH143gaxZz9b0nsR8X5EfCnpGUmLB9DH0IuIzZIOHrZ4saR11e11Gv/P0nctehsKEbEvIt6sbn8m6Ztpxgf63BX66otBhH2epI8m3N+j4ZrvPST9yfYbtkcH3cwk5kTEPmn8P4+k2QPu53Btp/Hup8OmGR+a566T6c+7NYiwTzaV1DCN/50bET+SdJmkm6qXq5iaKU3j3S+TTDM+FDqd/rxbgwj7HknzJ9w/RdLeAfQxqYjYW13vl/S8hm8q6k++mUG3ut4/4H7+YZim8Z5smnENwXM3yOnPBxH2rZIW2f6B7RMk/VzSxgH08R22T6oOnMj2SZJ+ouGbinqjpGXV7WWSXhhgL98yLNN4t5pmXAN+7gY+/XlE9P0i6XKNH5H/X0l3DqKHFn39i6T/ri47B92bpPUaf1n3fxp/RbRc0j9JelnSu9X1zCHq7T8lbZf0lsaDNXdAvZ2n8beGb0naVl0uH/RzV+irL88bp8sCSXAGHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8f8wCSRMeV1xuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit=train_images[9]\n",
    "\n",
    "#cmap=plt.cm.binary: 색상을 흑백으로 출력\n",
    "plt.imshow(digit, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이미지를 사용하려면 2차원 이미지 데이터를 1차원으로 변환\n",
    "train_images=train_images.reshape((60000,28*28))\n",
    "test_images=test_images.reshape((10000,28*28))\n",
    "\n",
    "train_images.shape,test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 189, 190,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 143, 247, 153,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 136, 247, 242,  86,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 192, 252, 187,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  62, 185,  18,   0,   0,   0,   0,  89, 236, 217,  47,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 216, 253,  60,   0,   0,   0,   0, 212, 255,\n",
       "        81,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 206, 252,  68,   0,   0,   0,  48,\n",
       "       242, 253,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 131, 251, 212,  21,   0,   0,\n",
       "        11, 167, 252, 197,   5,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  29, 232, 247,  63,   0,\n",
       "         0,   0, 153, 252, 226,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  45, 219, 252, 143,\n",
       "         0,   0,   0, 116, 249, 252, 103,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  96, 253, 255,\n",
       "       253, 200, 122,   7,  25, 201, 250, 158,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  92, 252,\n",
       "       252, 253, 217, 252, 252, 200, 227, 252, 231,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87,\n",
       "       251, 247, 231,  65,  48, 189, 252, 252, 253, 252, 251, 227,  35,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 190, 221,  98,   0,   0,   0,  42, 196, 252, 253, 252, 252,\n",
       "       162,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 111,  29,   0,   0,   0,   0,  62, 239, 252,  86,\n",
       "        42,  42,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 148, 253,\n",
       "       218,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121,\n",
       "       252, 231,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        31, 221, 251, 129,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 218, 252, 160,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 122, 252,  82,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지의 픽셀값은 0-255로 구성 \n",
    "#기계는 0과 1사이값으로 된 숫자로 변환해주는 것이 좋음(가장 큰 값으로 나눔)\n",
    "train_images=train_images.astype(\"float32\")/255\n",
    "test_images=test_images.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.7411765 ,\n",
       "       0.74509805, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.56078434, 0.96862745, 0.6       , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.53333336, 0.96862745,\n",
       "       0.9490196 , 0.3372549 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.7529412 , 0.9882353 , 0.73333335, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.24313726, 0.7254902 , 0.07058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34901962, 0.9254902 ,\n",
       "       0.8509804 , 0.18431373, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.84705883,\n",
       "       0.99215686, 0.23529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.83137256, 1.        , 0.31764707, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.80784315, 0.9882353 , 0.26666668,\n",
       "       0.        , 0.        , 0.        , 0.1882353 , 0.9490196 ,\n",
       "       0.99215686, 0.34901962, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5137255 ,\n",
       "       0.9843137 , 0.83137256, 0.08235294, 0.        , 0.        ,\n",
       "       0.04313726, 0.654902  , 0.9882353 , 0.77254903, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11372549, 0.9098039 , 0.96862745, 0.24705882,\n",
       "       0.        , 0.        , 0.        , 0.6       , 0.9882353 ,\n",
       "       0.8862745 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1764706 , 0.85882354,\n",
       "       0.9882353 , 0.56078434, 0.        , 0.        , 0.        ,\n",
       "       0.45490196, 0.9764706 , 0.9882353 , 0.40392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "       0.3764706 , 0.99215686, 1.        , 0.99215686, 0.78431374,\n",
       "       0.47843137, 0.02745098, 0.09803922, 0.7882353 , 0.98039216,\n",
       "       0.61960787, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.36078432, 0.9882353 , 0.9882353 ,\n",
       "       0.99215686, 0.8509804 , 0.9882353 , 0.9882353 , 0.78431374,\n",
       "       0.8901961 , 0.9882353 , 0.90588236, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34117648,\n",
       "       0.9843137 , 0.96862745, 0.90588236, 0.25490198, 0.1882353 ,\n",
       "       0.7411765 , 0.9882353 , 0.9882353 , 0.99215686, 0.9882353 ,\n",
       "       0.9843137 , 0.8901961 , 0.13725491, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.74509805, 0.8666667 , 0.38431373,\n",
       "       0.        , 0.        , 0.        , 0.16470589, 0.76862746,\n",
       "       0.9882353 , 0.99215686, 0.9882353 , 0.9882353 , 0.63529414,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.43529412, 0.11372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.24313726, 0.9372549 , 0.9882353 , 0.3372549 ,\n",
       "       0.16470589, 0.16470589, 0.05490196, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05882353, 0.5803922 ,\n",
       "       0.99215686, 0.85490197, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.4745098 , 0.9882353 , 0.90588236, 0.10980392,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12156863, 0.8666667 ,\n",
       "       0.9843137 , 0.5058824 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.85490197, 0.9882353 , 0.627451  , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.47843137,\n",
       "       0.9882353 , 0.32156864, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#다중분류(10개)\n",
    "# 라벨을 원핫 인코딩\n",
    "train_labels_en=pd.get_dummies(train_labels)\n",
    "test_labels_en=pd.get_dummies(test_labels)\n",
    "train_labels_en.shape,test_labels_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 신경망 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기화를 위한 seed 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#신경망 설계\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model=Sequential()\n",
    "#입력층\n",
    "model.add(Dense(1568,input_dim=784,activation=\"relu\"))\n",
    "#은닉층\n",
    "model.add(Dense(3136,activation=\"relu\"))\n",
    "#출력층\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001590F5B0A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001590F5B0A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1742 - acc: 0.9463\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0699 - acc: 0.9781\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0514 - acc: 0.9838\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0356 - acc: 0.9888\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0301 - acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1590f5f1ba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels_en,epochs=5,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000159125E2D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000159125E2D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0753 - acc: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07534349709749222, 0.9793000221252441]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "#입력층\n",
    "model2.add(Dense(1568,input_dim=784,activation=\"relu\"))\n",
    "#은닉층\n",
    "model2.add(Dense(3136,activation=\"relu\"))\n",
    "#출력층\n",
    "model2.add(Dense(10,activation=\"softmax\"))\n",
    "model2.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015912817EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015912817EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2228 - acc: 0.9336\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0905 - acc: 0.9742\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0644 - acc: 0.9819\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0516 - acc: 0.9862\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0435 - acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15912830320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_images,train_labels_en,epochs=5,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001590F1A8400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001590F1A8400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11093610525131226, 0.9783999919891357]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_images,test_labels_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) 평가 / 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0207 - acc: 0.9934\n",
      "훈련 정확도 :  [0.0207159873098135, 0.993399977684021]\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0753 - acc: 0.9793\n",
      "테스트 정확도 :  [0.07534349709749222, 0.9793000221252441]\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 정확도 : \",model.evaluate(train_images, train_labels_en))\n",
    "print(\"테스트 정확도 : \",model.evaluate(test_images, test_labels_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001593278BC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001593278BC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[[2.3646590e-08 9.9997354e-01 2.4100278e-05 8.7955571e-10 4.0801785e-07\n",
      "  2.7294948e-07 4.9190919e-07 7.9191278e-07 4.1319336e-07 7.8111402e-09]]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(test_images[2:3]) #1\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15939592d68>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit=test_images[2].reshape(28,28)\n",
    "\n",
    "#cmap=plt.cm.binary: 색상을 흑백으로 출력\n",
    "plt.imshow(digit, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159327a72b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=pimg.open(\"./data/3.jpg\").convert(\"L\")#흑백으로 바꾸기\n",
    "plt.imshow(img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15939608a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2=pimg.open(\"./data/6.jpg\").convert(\"L\")#흑백으로 바꾸기\n",
    "plt.imshow(img2,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이미지 타입을 numpy 배열로 변환\n",
    "num=np.array(img)\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2=np.array(img2)\n",
    "num2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 255,\n",
       "        254, 255, 254, 255, 255, 255, 255, 252, 254, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 255, 251,\n",
       "        253, 161,  32,   1,  28, 151, 251, 255, 255, 252, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 255, 158,  32,\n",
       "          6,   0,   0,   0,   5,   0, 140, 254, 253, 255, 254, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 128,   0,   1,\n",
       "          0,   0,   2,   0,   0,   0,   6, 255, 255, 253, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 124,   0,   2,   2,\n",
       "          0,   4,  88, 240,   0,   3,   0, 254, 255, 255, 253, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 151,   3,   3,   0,  72,\n",
       "        247, 253, 255, 255,   0,   0,   1, 255, 252, 254, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255,  33,   0,   0,  71, 247,\n",
       "        255, 252, 255, 252,  15,   1,   0, 134, 253, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 127,   1,  83, 246, 255,\n",
       "        255, 255, 254, 255, 109,   0,   1,   8, 254, 255, 254, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 254, 233, 253, 254, 255,\n",
       "        255, 255, 253, 253, 249,   0,   1,   0, 255, 253, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 252, 255, 255, 255, 254,\n",
       "        254, 255, 255, 255, 254,   0,   0,   2, 252, 255, 253, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 250, 255, 252,\n",
       "        255, 255, 254, 252, 254,   3,   1,   2, 255, 253, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 251, 255, 255, 255,\n",
       "        255, 255, 254, 255, 233,   0,   0,   0, 254, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 255, 254, 253,\n",
       "        255, 255, 255, 254, 107,   6,   1,  46, 255, 255, 252, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 252, 255, 249, 255, 255,\n",
       "        254, 253, 255, 232,   8,   0,   0, 180, 255, 250, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 254, 253, 255, 158,  34,\n",
       "          1,   2,  31,  61,   3,   1,  46, 254, 253, 255, 253, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 127,   0,   0,\n",
       "          0,   0,   1,   3,   0,   1, 176, 254, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [253, 255, 255, 255, 251, 255, 253, 255, 183,  31,   0,   0,   1,\n",
       "          0,   0,   1,   0,   2,  48, 255, 254, 252, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 253, 252, 251, 255, 255, 255, 254,  22,   3,   1,   0,   0,\n",
       "          0,   3,   0,   0,   0,   7, 255, 255, 255, 255, 254, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 252, 251, 255,  13,   0,   0,   0,   3,\n",
       "          0,  34, 160,   0,   0,   2, 255, 255, 255, 255, 251, 255, 255,\n",
       "        255, 255],\n",
       "       [251, 255, 255, 249, 254, 255, 255, 255, 133,   4,   0,   3,  87,\n",
       "        245, 254, 252,   1,   2,   0, 255, 254, 252, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 253, 255, 253, 253, 255, 254, 255, 253, 253, 253, 253,\n",
       "        255, 255, 255,   0,   0,   5, 253, 255, 255, 254, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [254, 255, 252, 255, 255, 252, 255, 254, 253, 255, 255, 255, 253,\n",
       "        255, 254, 182,   0,   0,   0, 252, 255, 255, 255, 250, 255, 255,\n",
       "        255, 255],\n",
       "       [253, 254, 255, 181,  32,  37, 101, 190, 255, 254, 254, 249, 255,\n",
       "        255, 177,  20,   2,   1,   0, 255, 252, 253, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 253, 254,  37,   0,   0,   0,   1,   0,   2,   2,   0,   1,\n",
       "          0,   3,   0,   0,   2, 102, 255, 255, 255, 250, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 254, 255, 134,   4,   0,   4,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 108, 251, 255, 255, 255, 254, 254, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 252, 255, 255, 251, 208, 112,  31,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1, 107, 251, 255, 253, 251, 255, 254, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [254, 255, 251, 254, 255, 254, 255, 255, 254, 254, 254, 254, 254,\n",
       "        254, 254, 254, 253, 252, 255, 255, 255, 255, 254, 253, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 253, 255, 255, 253, 255, 255, 251, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 254, 253, 255, 254, 253, 255, 255, 255, 255,\n",
       "        255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검정색이 0이므로 숫자부분이 0으로 표현\n",
    "# 기존데이터에는 숫자부분이 흰색(255)로 되어있음\n",
    "# 숫자부분을 0에서 255로 변환 필요\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "          1,   0,   1,   0,   0,   0,   0,   3,   1,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   4,\n",
       "          2,  94, 223, 254, 227, 104,   4,   0,   0,   3,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,  97, 223,\n",
       "        249, 255, 255, 255, 250, 255, 115,   1,   2,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 127, 255, 254,\n",
       "        255, 255, 253, 255, 255, 255, 249,   0,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 131, 255, 253, 253,\n",
       "        255, 251, 167,  15, 255, 252, 255,   1,   0,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 104, 252, 252, 255, 183,\n",
       "          8,   2,   0,   0, 255, 255, 254,   0,   3,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 222, 255, 255, 184,   8,\n",
       "          0,   3,   0,   3, 240, 254, 255, 121,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 128, 254, 172,   9,   0,\n",
       "          0,   0,   1,   0, 146, 255, 254, 247,   1,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,  22,   2,   1,   0,\n",
       "          0,   0,   2,   2,   6, 255, 254, 255,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   1,\n",
       "          1,   0,   0,   0,   1, 255, 255, 253,   3,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0,   3,\n",
       "          0,   0,   1,   3,   1, 252, 254, 253,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,\n",
       "          0,   0,   1,   0,  22, 255, 255, 255,   1,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   1,   2,\n",
       "          0,   0,   0,   1, 148, 249, 254, 209,   0,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   6,   0,   0,\n",
       "          1,   2,   0,  23, 247, 255, 255,  75,   0,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   0,  97, 221,\n",
       "        254, 253, 224, 194, 252, 254, 209,   1,   2,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 255, 255,\n",
       "        255, 255, 254, 252, 255, 254,  79,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,   0,   0,   4,   0,   2,   0,  72, 224, 255, 255, 254,\n",
       "        255, 255, 254, 255, 253, 207,   0,   1,   3,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   3,   4,   0,   0,   0,   1, 233, 252, 254, 255, 255,\n",
       "        255, 252, 255, 255, 255, 248,   0,   0,   0,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   4,   0, 242, 255, 255, 255, 252,\n",
       "        255, 221,  95, 255, 255, 253,   0,   0,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  4,   0,   0,   6,   1,   0,   0,   0, 122, 251, 255, 252, 168,\n",
       "         10,   1,   3, 254, 253, 255,   0,   1,   3,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,   2,   2,   0,   1,   0,   2,   2,   2,   2,\n",
       "          0,   0,   0, 255, 255, 250,   2,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   3,   0,   0,   3,   0,   1,   2,   0,   0,   0,   2,\n",
       "          0,   1,  73, 255, 255, 255,   3,   0,   0,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   1,   0,  74, 223, 218, 154,  65,   0,   1,   1,   6,   0,\n",
       "          0,  78, 235, 253, 254, 255,   0,   3,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   1, 218, 255, 255, 255, 254, 255, 253, 253, 255, 254,\n",
       "        255, 252, 255, 255, 253, 153,   0,   0,   0,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   1,   0, 121, 251, 255, 251, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 147,   4,   0,   0,   0,   1,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   3,   0,   0,   4,  47, 143, 224, 254, 254, 254, 254, 254,\n",
       "        254, 254, 254, 148,   4,   0,   2,   4,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   4,   1,   0,   1,   0,   0,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   2,   3,   0,   0,   0,   0,   1,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   2,   0,   0,   4,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   2,   0,   1,   2,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=255-num\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2=255-num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작성한 숫자데이터 훈련했던 데이터와 동일하게 변환(크기:1차원, 값범위 :0~1)\n",
    "test_num=num.reshape(1,28*28)\n",
    "test_num2=num2.reshape(1,28*28)\n",
    "test_num=test_num.astype(\"float32\")/255\n",
    "test_num2=test_num2.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6296534e-19, 1.0146954e-13, 3.8192763e-08, 1.0000000e+00,\n",
       "        3.8440494e-24, 1.6774550e-13, 2.5812011e-20, 6.5964734e-12,\n",
       "        4.7946141e-08, 5.9510993e-17]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(test_num)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0115242e-07, 4.0832583e-06, 1.2867973e-07, 3.7152984e-07,\n",
       "        4.1860079e-07, 2.3025563e-01, 7.5755543e-01, 6.7900726e-07,\n",
       "        1.2140083e-02, 4.2924468e-05]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2=model.predict(test_num2)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN을 이용해서 손글씨 숫자 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련데이터 1000개, 테스트데이터 300개\n",
    "X_train=X_train[:1000,:]\n",
    "y_train=y_train[:1000,]\n",
    "X_test=X_test[:300,:]\n",
    "y_test=y_test[:300,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0],X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (300, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#2차원 데이터에 색상 차원을 추가(흑백 1차원,칼라 3차원)\n",
    "X_train=X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],28,28,1)\n",
    "\n",
    "#0-255범위의 픽셀값을 0~1사이 범위로 변경\n",
    "X_train=X_train.astype(\"float32\")/255\n",
    "X_test=X_test.astype(\"float32\")/255\n",
    "\n",
    "#다중분류이므로 원핫 인코딩\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력층에 CNN을 추가해서 학습모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "cnn_model=Sequential()\n",
    "\n",
    "#입력층(CNN층)\n",
    "#filters : 필터의 수, 출력의 수 (출력되는 이미지의 개수)\n",
    "#kernel_size : 필터의 크기 (3,3) (5,5) (7,7)\n",
    "#input_shape : 입력데이터의 크기(2차원 이상인 경우에 사용)\n",
    "#padding : converlution 연산때문에 작아지는 이미지 크기를 유지할 것인지 여부\n",
    "#          (same-항상 같은 크기로 이미지를 유지,\n",
    "#           valid-컨벌루션으로 줄어든 상태를 그대로 유지)\n",
    "cnn_model.add(Conv2D(filters=32,\n",
    "                    kernel_size=(3,3),\n",
    "                    input_shape=(28,28,1),\n",
    "                    padding=\"valid\",\n",
    "                    activation=\"relu\"))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#pool_size : 이미지를 얼마나 줄일 것인지를 설정\n",
    "\n",
    "#은닉층 넣기 전에 이전 데이터들을 1차원으로 변환\n",
    "cnn_model.add(Flatten())\n",
    "#은닉층\n",
    "cnn_model.add(Dense(units=128,activation=\"relu\"))\n",
    "#출력층\n",
    "cnn_model.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B0DE016A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B0DE016A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 1.1683 - acc: 0.6622WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001592EC96620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001592EC96620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 1.0114 - acc: 0.7070 - val_loss: 0.5253 - val_acc: 0.8300\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3487 - acc: 0.9000 - val_loss: 0.3739 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2179 - acc: 0.9360 - val_loss: 0.3887 - val_acc: 0.8567\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1592 - acc: 0.9530 - val_loss: 0.2991 - val_acc: 0.9100\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0892 - acc: 0.9810 - val_loss: 0.2862 - val_acc: 0.9067\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0644 - acc: 0.9860 - val_loss: 0.2890 - val_acc: 0.9033\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0314 - acc: 0.9990 - val_loss: 0.2334 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 0.9980 - val_loss: 0.2434 - val_acc: 0.9267\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.2438 - val_acc: 0.9233\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.2447 - val_acc: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1592ec00780>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train,y_train,epochs=10,batch_size=20,\n",
    "             validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 728,266\n",
      "Trainable params: 728,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model2=Sequential()\n",
    "\n",
    "#입력층(CNN층)\n",
    "#filters : 필터의 수, 출력의 수 (출력되는 이미지의 개수)\n",
    "#kernel_size : 필터의 크기 (3,3) (5,5) (7,7)\n",
    "#input_shape : 입력데이터의 크기(2차원 이상인 경우에 사용)\n",
    "#padding : converlution 연산때문에 작아지는 이미지 크기를 유지할 것인지 여부\n",
    "#          (same-항상 같은 크기로 이미지를 유지,\n",
    "#           valid-컨벌루션으로 줄어든 상태를 그대로 유지)\n",
    "cnn_model2.add(Conv2D(filters=32,\n",
    "                    kernel_size=(3,3),\n",
    "                    input_shape=(28,28,1),\n",
    "                    padding=\"valid\",\n",
    "                    activation=\"relu\"))\n",
    "cnn_model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#pool_size : 이미지를 얼마나 줄일 것인지를 설정\n",
    "\n",
    "#은닉층 넣기 전에 이전 데이터들을 1차원으로 변환\n",
    "cnn_model2.add(Flatten())\n",
    "#은닉층\n",
    "cnn_model2.add(Dense(units=128,activation=\"relu\"))\n",
    "cnn_model2.add(Dropout(0.2))\n",
    "cnn_model2.add(Dense(units=256,activation=\"relu\"))\n",
    "#출력층\n",
    "cnn_model2.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "cnn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model2.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000159301A51E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000159301A51E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "33/50 [==================>...........] - ETA: 0s - loss: 1.5047 - acc: 0.5470WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001593083FEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001593083FEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 1.2466 - acc: 0.6250 - val_loss: 0.6477 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4644 - acc: 0.8580 - val_loss: 0.4052 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3164 - acc: 0.9070 - val_loss: 0.3641 - val_acc: 0.8767\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2152 - acc: 0.9410 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1624 - acc: 0.9480 - val_loss: 0.2640 - val_acc: 0.9233\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1255 - acc: 0.9610 - val_loss: 0.2664 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0747 - acc: 0.9770 - val_loss: 0.2725 - val_acc: 0.9100\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0666 - acc: 0.9830 - val_loss: 0.2391 - val_acc: 0.9300\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0503 - acc: 0.9830 - val_loss: 0.2213 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0351 - acc: 0.9920 - val_loss: 0.2337 - val_acc: 0.9267\n"
     ]
    }
   ],
   "source": [
    "h=cnn_model2.fit(X_train,y_train,epochs=10,batch_size=20,\n",
    "             validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1593044cc88>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=h.history[\"acc\"]\n",
    "val_acc=h.history[\"val_acc\"]\n",
    "\n",
    "epochs=np.arange(len(acc))\n",
    "\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Train\")\n",
    "plt.plot(epochs,val_acc,c=\"pink\",label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베스트 모델을 찾아 저장하고,더이상 학습이 되지 않는다면 중단하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#모델을 저장할 폴더명\n",
    "MODEL_FOLDER=\"./model/\"\n",
    "#해당 폴더가 없다면 해당 폴더를 생성\n",
    "if not os.path.exists(MODEL_FOLDER):\n",
    "    os.mkdir(MODEL_FOLDER)\n",
    "    \n",
    "#저장할 파일명 설정\n",
    "#{epoch:04d} : 반복수를 4자리로 표시\n",
    "#{acc:.4f} : 정확도를 소수점 4째자리까지 표시\n",
    "modelpath = MODEL_FOLDER+\"cnn-{epoch:04d}-{val_acc:.4f}.hdf5\"\n",
    "\n",
    "#베스트를 찾아서 해당파일명으로 저장\n",
    "#save_best_only : 더 나은 결과값만 저장\n",
    "#ModelCheckpoint(filepath=파일패스,monitor=기준값,save_best_only=True/False)\n",
    "mc=ModelCheckpoint(filepath=modelpath,\n",
    "                  monitor=\"val_acc\",\n",
    "                   #회귀일 경우 monitor=\"loss\"를 사용\n",
    "                  save_best_only=True,\n",
    "                  verbose=1)\n",
    "# EarlyStopping(monitor=기준값, patience=조금 더 기다리는 횟수)\n",
    "# patience=20 : 학습이 더 나아지지 않더라도 20회는 더 반복해줌\n",
    "es = EarlyStopping(monitor=\"val_acc\",patience=20)\n",
    "cnn_model3=Sequential()\n",
    "\n",
    "#입력층(CNN층)\n",
    "#filters : 필터의 수, 출력의 수 (출력되는 이미지의 개수)\n",
    "#kernel_size : 필터의 크기 (3,3) (5,5) (7,7)\n",
    "#input_shape : 입력데이터의 크기(2차원 이상인 경우에 사용)\n",
    "#              (가로,세로,색상->1(흑백),3(칼라))\n",
    "#padding : converlution 연산때문에 작아지는 이미지 크기를 유지할 것인지 여부\n",
    "#          (same-항상 같은 크기로 이미지를 유지,\n",
    "#           valid-컨벌루션으로 줄어든 상태를 그대로 유지)\n",
    "cnn_model3.add(Conv2D(filters=32,\n",
    "                    kernel_size=(3,3),\n",
    "                    input_shape=(28,28,1),\n",
    "                    padding=\"valid\",\n",
    "                    activation=\"relu\"))\n",
    "cnn_model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#pool_size : 이미지를 얼마나 줄일 것인지를 설정\n",
    "\n",
    "#은닉층 넣기 전에 이전 데이터들을 1차원으로 변환\n",
    "cnn_model3.add(Flatten())\n",
    "#은닉층\n",
    "cnn_model3.add(Dense(units=128,activation=\"relu\"))\n",
    "cnn_model3.add(Dropout(0.2))\n",
    "cnn_model3.add(Dense(units=256,activation=\"relu\"))\n",
    "cnn_model3.add(Dropout(0.2))\n",
    "cnn_model3.add(Dense(units=128,activation=\"relu\"))\n",
    "#출력층\n",
    "cnn_model3.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "cnn_model3.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001592ED22510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001592ED22510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "25/50 [==============>...............] - ETA: 0s - loss: 1.9275 - acc: 0.3760WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015931F10378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015931F10378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72333, saving model to ./model\\cnn-0001-0.7233.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.4523 - acc: 0.5330 - val_loss: 0.7398 - val_acc: 0.7233\n",
      "Epoch 2/50\n",
      "33/50 [==================>...........] - ETA: 0s - loss: 0.5615 - acc: 0.8227\n",
      "Epoch 00002: val_acc improved from 0.72333 to 0.84000, saving model to ./model\\cnn-0002-0.8400.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5458 - acc: 0.8380 - val_loss: 0.4943 - val_acc: 0.8400\n",
      "Epoch 3/50\n",
      "29/50 [================>.............] - ETA: 0s - loss: 0.3840 - acc: 0.8776\n",
      "Epoch 00003: val_acc improved from 0.84000 to 0.85000, saving model to ./model\\cnn-0003-0.8500.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3623 - acc: 0.8860 - val_loss: 0.3527 - val_acc: 0.8500\n",
      "Epoch 4/50\n",
      "29/50 [================>.............] - ETA: 0s - loss: 0.2171 - acc: 0.9379\n",
      "Epoch 00004: val_acc improved from 0.85000 to 0.92333, saving model to ./model\\cnn-0004-0.9233.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2373 - acc: 0.9310 - val_loss: 0.2752 - val_acc: 0.9233\n",
      "Epoch 5/50\n",
      "33/50 [==================>...........] - ETA: 0s - loss: 0.1571 - acc: 0.9515\n",
      "Epoch 00005: val_acc did not improve from 0.92333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1936 - acc: 0.9410 - val_loss: 0.2739 - val_acc: 0.9200\n",
      "Epoch 6/50\n",
      "25/50 [==============>...............] - ETA: 0s - loss: 0.1270 - acc: 0.9660\n",
      "Epoch 00006: val_acc did not improve from 0.92333\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1342 - acc: 0.9600 - val_loss: 0.2911 - val_acc: 0.9033\n",
      "Epoch 7/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.1125 - acc: 0.9589\n",
      "Epoch 00007: val_acc improved from 0.92333 to 0.93667, saving model to ./model\\cnn-0007-0.9367.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0967 - acc: 0.9670 - val_loss: 0.1944 - val_acc: 0.9367\n",
      "Epoch 8/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0662 - acc: 0.9750\n",
      "Epoch 00008: val_acc improved from 0.93667 to 0.95000, saving model to ./model\\cnn-0008-0.9500.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0740 - acc: 0.9730 - val_loss: 0.1862 - val_acc: 0.9500\n",
      "Epoch 9/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0448 - acc: 0.9857\n",
      "Epoch 00009: val_acc improved from 0.95000 to 0.96333, saving model to ./model\\cnn-0009-0.9633.hdf5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0590 - acc: 0.9790 - val_loss: 0.1813 - val_acc: 0.9633\n",
      "Epoch 10/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0316 - acc: 0.9893\n",
      "Epoch 00010: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0297 - acc: 0.9910 - val_loss: 0.2168 - val_acc: 0.9367\n",
      "Epoch 11/50\n",
      "24/50 [=============>................] - ETA: 0s - loss: 0.0390 - acc: 0.9875\n",
      "Epoch 00011: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0389 - acc: 0.9900 - val_loss: 0.1963 - val_acc: 0.9467\n",
      "Epoch 12/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0402 - acc: 0.9875\n",
      "Epoch 00012: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0373 - acc: 0.9890 - val_loss: 0.2302 - val_acc: 0.9367\n",
      "Epoch 13/50\n",
      "27/50 [===============>..............] - ETA: 0s - loss: 0.0435 - acc: 0.9852\n",
      "Epoch 00013: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0326 - acc: 0.9900 - val_loss: 0.2435 - val_acc: 0.9400\n",
      "Epoch 14/50\n",
      "31/50 [=================>............] - ETA: 0s - loss: 0.0514 - acc: 0.9855\n",
      "Epoch 00014: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0400 - acc: 0.9900 - val_loss: 0.2168 - val_acc: 0.9400\n",
      "Epoch 15/50\n",
      "29/50 [================>.............] - ETA: 0s - loss: 0.0383 - acc: 0.9897\n",
      "Epoch 00015: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0325 - acc: 0.9920 - val_loss: 0.2360 - val_acc: 0.9400\n",
      "Epoch 16/50\n",
      "27/50 [===============>..............] - ETA: 0s - loss: 0.0253 - acc: 0.9944\n",
      "Epoch 00016: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 0.9960 - val_loss: 0.1904 - val_acc: 0.9367\n",
      "Epoch 17/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0068 - acc: 0.9982\n",
      "Epoch 00017: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0142 - acc: 0.9950 - val_loss: 0.2689 - val_acc: 0.9333\n",
      "Epoch 18/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0211 - acc: 0.9964\n",
      "Epoch 00018: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0153 - acc: 0.9980 - val_loss: 0.2238 - val_acc: 0.9500\n",
      "Epoch 19/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0212 - acc: 0.9946    \n",
      "Epoch 00019: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.2011 - val_acc: 0.9533\n",
      "Epoch 20/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0250 - acc: 0.9911\n",
      "Epoch 00020: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0251 - acc: 0.9900 - val_loss: 0.3009 - val_acc: 0.9267\n",
      "Epoch 21/50\n",
      "27/50 [===============>..............] - ETA: 0s - loss: 0.0185 - acc: 0.9944    \n",
      "Epoch 00021: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.1898 - val_acc: 0.9533\n",
      "Epoch 22/50\n",
      "31/50 [=================>............] - ETA: 0s - loss: 0.0086 - acc: 0.9968    \n",
      "Epoch 00022: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0119 - acc: 0.9950 - val_loss: 0.2550 - val_acc: 0.9433\n",
      "Epoch 23/50\n",
      "30/50 [=================>............] - ETA: 0s - loss: 0.0091 - acc: 0.9967\n",
      "Epoch 00023: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0079 - acc: 0.9970 - val_loss: 0.2780 - val_acc: 0.9367\n",
      "Epoch 24/50\n",
      "31/50 [=================>............] - ETA: 0s - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 00024: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.3269 - val_acc: 0.9267\n",
      "Epoch 25/50\n",
      "29/50 [================>.............] - ETA: 0s - loss: 0.0096 - acc: 0.9948\n",
      "Epoch 00025: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0113 - acc: 0.9940 - val_loss: 0.2748 - val_acc: 0.9333\n",
      "Epoch 26/50\n",
      "30/50 [=================>............] - ETA: 0s - loss: 0.0085 - acc: 0.9983\n",
      "Epoch 00026: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.3007 - val_acc: 0.9167\n",
      "Epoch 27/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0192 - acc: 0.9929    \n",
      "Epoch 00027: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0179 - acc: 0.9930 - val_loss: 0.3566 - val_acc: 0.9100\n",
      "Epoch 28/50\n",
      "32/50 [==================>...........] - ETA: 0s - loss: 0.0193 - acc: 0.9937\n",
      "Epoch 00028: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9890 - val_loss: 0.3087 - val_acc: 0.9033\n",
      "Epoch 29/50\n",
      "28/50 [===============>..............] - ETA: 0s - loss: 0.0379 - acc: 0.9857\n",
      "Epoch 00029: val_acc did not improve from 0.96333\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0313 - acc: 0.9880 - val_loss: 0.2365 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "h=cnn_model3.fit(X_train,y_train,epochs=50,batch_size=20,\n",
    "             validation_data=(X_test,y_test),\n",
    "                    callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15931b0d898>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=h.history[\"acc\"]\n",
    "val_acc=h.history[\"val_acc\"]\n",
    "\n",
    "epochs=np.arange(len(acc))\n",
    "\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Train\")\n",
    "plt.plot(epochs,val_acc,c=\"pink\",label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
